# ì •ì„¸ë‹´ ì •ì±… í”„ë¡œê·¸ë¨ - ë‹¨ì¼ íŒŒì¼ ë²„ì „ (Streamlit Cloud í˜¸í™˜)
# modules, config ì—†ì´ ëª¨ë“  ê¸°ëŠ¥ í†µí•©

import streamlit as st
import os
import json
import sqlite3
import base64
from datetime import datetime, date
from io import BytesIO
from typing import Dict, Any, Optional, List, Tuple
from contextlib import contextmanager
from zipfile import ZipFile
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# OpenAI import
try:
    from openai import OpenAI
    api_key = os.environ.get("OPENAI_API_KEY")
    if not api_key and hasattr(st, 'secrets'):
        api_key = st.secrets.get("OPENAI_API_KEY", "")
    if not api_key:
        st.error("âš ï¸ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit Cloud Secretsì—ì„œ ì„¤ì •í•˜ì„¸ìš”.")
        st.stop()
    client = OpenAI(api_key=api_key)
except Exception as e:
    st.error(f"OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
    st.stop()

# PIL import
try:
    from PIL import Image
except:
    st.error("Pillow ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. requirements.txtì— pillow>=10.0.0 ì¶”ê°€í•˜ì„¸ìš”.")
    st.stop()

# ReportLab import
try:
    from reportlab.lib.pagesizes import A4
    from reportlab.lib.units import mm
    from reportlab.pdfgen import canvas
    from reportlab.pdfbase import pdfmetrics
    from reportlab.pdfbase.cidfonts import UnicodeCIDFont
except:
    st.error("ReportLab ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. requirements.txtì— reportlab>=4.0.0 ì¶”ê°€í•˜ì„¸ìš”.")
    st.stop()

# ==================== ì„¤ì • (Settings) ====================

DB_PATH = "data/policies.db"

TARGET_AUDIENCES = {
    "ì‹œë¯¼": {
        "tone": "ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´",
        "focus": "ì¼ìƒ ìƒí™œ í˜œíƒ, ì‹¤ìƒí™œ ë³€í™”"
    },
    "ì²­ë…„": {
        "tone": "íŠ¸ë Œë””í•˜ê³  ì§ê´€ì ì¸",
        "focus": "ê¸°íšŒ í™•ëŒ€, ë¯¸ë˜ ì „ë§"
    },
    "ë…¸ì¸": {
        "tone": "ì¹œì ˆí•˜ê³  ë”°ëœ»í•œ",
        "focus": "ì•ˆì „, í¸ì˜ì„±, ì ‘ê·¼ì„±"
    },
    "í•™ë¶€ëª¨": {
        "tone": "ì‹ ë¢°ê° ìˆê³  êµ¬ì²´ì ì¸",
        "focus": "ìë…€ ì•ˆì „, êµìœ¡ íš¨ê³¼"
    },
    "ê¸°ì—…": {
        "tone": "ì „ë¬¸ì ì´ê³  íš¨ìœ¨ì ì¸",
        "focus": "ë¹„ìš© ì ˆê°, ê·œì œ ì™„í™”, ROI"
    },
    "ì§€ìì²´ ê³µë¬´ì›": {
        "tone": "ì²´ê³„ì ì´ê³  ì‹¤ë¬´ì ì¸",
        "focus": "ì‹¤í–‰ ê°€ëŠ¥ì„±, ì˜ˆì‚°, ë²•ì  ê·¼ê±°"
    },
    "ì˜íšŒ/ì˜ì›": {
        "tone": "ì„¤ë“ì ì´ê³  ê·¼ê±° ì¤‘ì‹¬",
        "focus": "ì •ì±… íš¨ê³¼, êµ­ë¯¼ ì²´ê°, ì„±ê³¼ ì§€í‘œ"
    }
}

VIDEO_PLATFORMS = {
    "Sora": "https://sora.chatgpt.com",
    "Runway": "https://runwayml.com",
    "Pika": "https://pika.art",
    "Luma Dream Machine": "https://lumalabs.ai"
}

IMAGE_SIZES = ["1024x1024", "1024x1792", "1792x1024"]
VIDEO_DURATIONS = ["10ì´ˆ", "20ì´ˆ", "30ì´ˆ", "60ì´ˆ"]

CONTENT_PACKAGES = {
    "A ë§ˆì¼€íŒ…": ["ì´ë¯¸ì§€ 2ì¥", "ì˜ìƒ 1ê°œ", "í™ë³´ ë¬¸êµ¬ 3ì¢…"],
    "B ì •ì±… ì„¤ëª…": ["ì •ì±… ìš”ì•½", "PPT êµ¬ì„±", "FAQ"],
    "C í’€ íŒ¨í‚¤ì§€": ["ì´ë¯¸ì§€ 4ì¥", "ì˜ìƒ 2ê°œ", "í™ë³´ ë¬¸êµ¬ 5ì¢…", "ì •ì±… ë¬¸ì„œ", "PPT", "ì„±ê³¼ ì§€í‘œ"]
}

DEFAULT_IMAGE_STYLE = """
PHOTO-REALISTIC Korean documentary style. Shot on Canon EOS R5, 35mm f/1.8, natural daylight.

Korean People: Natural Korean faces, realistic skin texture, genuine expressions, casual Korean clothing (NOT costumes). Ages 20s-60s with natural features. NO AI artifacts, NO perfect symmetry, NO filtered faces.

Location: Real Korean settings - apartments, offices, parks, cafes (Seoul/Busan style). Modern Korean architecture (2010s-2020s). Background: Korean streetscape, but NO readable text/signs.

Lighting: Soft natural light (morning/afternoon), realistic shadows, true Korean colors (neutral tones, NO oversaturation, NO HDR).

Composition: Eye-level, candid moment, subject sharp with subtle background blur. Documentary photography aesthetic.

FORBIDDEN: âŒ Cartoon/illustration/anime style âŒ 3D render âŒ Sci-fi/fantasy âŒ Stock photo poses âŒ Heavy makeup âŒ Studio lighting âŒ Visible text âŒ Foreign locations

Reference: Korean TV drama stills (Reply 1988, My Mister), Korean photojournalism (í•œê²¨ë ˆ/ê²½í–¥ì‹ ë¬¸).

MUST look like: Real photo taken in Korea TODAY with professional camera.
"""

# ==================== ë°ì´í„°ë² ì´ìŠ¤ (Database) ====================

@contextmanager
def get_db():
    # data í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
    os.makedirs("data", exist_ok=True)
    conn = sqlite3.connect(DB_PATH, check_same_thread=False)
    conn.row_factory = sqlite3.Row
    try:
        yield conn
    finally:
        conn.close()

def init_database():
    with get_db() as conn:
        conn.execute("""
            CREATE TABLE IF NOT EXISTS policies (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                title TEXT NOT NULL,
                category TEXT NOT NULL,
                target_audience TEXT NOT NULL,
                description TEXT,
                status TEXT DEFAULT 'draft',
                created_at TEXT NOT NULL,
                updated_at TEXT NOT NULL
            )
        """)
        
        conn.execute("""
            CREATE TABLE IF NOT EXISTS policy_contents (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                policy_id INTEGER NOT NULL,
                content_type TEXT NOT NULL,
                content_data TEXT NOT NULL,
                metadata TEXT,
                created_at TEXT NOT NULL,
                FOREIGN KEY (policy_id) REFERENCES policies(id)
            )
        """)
        
        conn.execute("""
            CREATE TABLE IF NOT EXISTS policy_performance (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                policy_id INTEGER NOT NULL,
                view_count INTEGER DEFAULT 0,
                engagement_score REAL DEFAULT 0.0,
                feedback_data TEXT,
                metrics_data TEXT,
                updated_at TEXT NOT NULL,
                FOREIGN KEY (policy_id) REFERENCES policies(id)
            )
        """)
        
        conn.execute("""
            CREATE TABLE IF NOT EXISTS generated_media (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                policy_id INTEGER NOT NULL,
                media_type TEXT NOT NULL,
                media_url TEXT,
                media_data BLOB,
                prompt TEXT,
                generation_params TEXT,
                created_at TEXT NOT NULL,
                FOREIGN KEY (policy_id) REFERENCES policies(id)
            )
        """)
        
        conn.commit()

def create_policy(title: str, category: str, target_audience: str, description: str = "") -> int:
    now = datetime.now().isoformat()
    with get_db() as conn:
        cursor = conn.execute("""
            INSERT INTO policies (title, category, target_audience, description, status, created_at, updated_at)
            VALUES (?, ?, ?, ?, 'draft', ?, ?)
        """, (title, category, target_audience, description, now, now))
        conn.commit()
        return cursor.lastrowid

def update_policy_status(policy_id: int, status: str):
    now = datetime.now().isoformat()
    with get_db() as conn:
        conn.execute("""
            UPDATE policies SET status = ?, updated_at = ? WHERE id = ?
        """, (status, now, policy_id))
        conn.commit()

def save_policy_content(policy_id: int, content_type: str, content_data: Dict[str, Any], metadata: Optional[Dict] = None):
    now = datetime.now().isoformat()
    with get_db() as conn:
        conn.execute("""
            INSERT INTO policy_contents (policy_id, content_type, content_data, metadata, created_at)
            VALUES (?, ?, ?, ?, ?)
        """, (
            policy_id,
            content_type,
            json.dumps(content_data, ensure_ascii=False),
            json.dumps(metadata or {}, ensure_ascii=False),
            now
        ))
        conn.commit()

def save_generated_media(policy_id: int, media_type: str, media_data: bytes, prompt: str, params: Dict[str, Any]):
    now = datetime.now().isoformat()
    with get_db() as conn:
        conn.execute("""
            INSERT INTO generated_media (policy_id, media_type, media_data, prompt, generation_params, created_at)
            VALUES (?, ?, ?, ?, ?, ?)
        """, (
            policy_id,
            media_type,
            media_data,
            prompt,
            json.dumps(params, ensure_ascii=False),
            now
        ))
        conn.commit()

def get_policy(policy_id: int) -> Optional[Dict[str, Any]]:
    with get_db() as conn:
        row = conn.execute("SELECT * FROM policies WHERE id = ?", (policy_id,)).fetchone()
        if row:
            return dict(row)
        return None

def get_all_policies(limit: int = 50) -> List[Dict[str, Any]]:
    with get_db() as conn:
        rows = conn.execute("""
            SELECT * FROM policies ORDER BY created_at DESC LIMIT ?
        """, (limit,)).fetchall()
        return [dict(row) for row in rows]

def get_policy_contents(policy_id: int) -> List[Dict[str, Any]]:
    with get_db() as conn:
        rows = conn.execute("""
            SELECT * FROM policy_contents WHERE policy_id = ? ORDER BY created_at DESC
        """, (policy_id,)).fetchall()
        results = []
        for row in rows:
            data = dict(row)
            data['content_data'] = json.loads(data['content_data'])
            data['metadata'] = json.loads(data['metadata']) if data['metadata'] else {}
            results.append(data)
        return results

def get_generated_media(policy_id: int, media_type: Optional[str] = None) -> List[Dict[str, Any]]:
    with get_db() as conn:
        if media_type:
            rows = conn.execute("""
                SELECT * FROM generated_media WHERE policy_id = ? AND media_type = ? ORDER BY created_at DESC
            """, (policy_id, media_type)).fetchall()
        else:
            rows = conn.execute("""
                SELECT * FROM generated_media WHERE policy_id = ? ORDER BY created_at DESC
            """, (policy_id,)).fetchall()
        
        results = []
        for row in rows:
            data = dict(row)
            data['generation_params'] = json.loads(data['generation_params']) if data['generation_params'] else {}
            results.append(data)
        return results

def get_policies_by_date(date_str: str) -> List[Dict[str, Any]]:
    with get_db() as conn:
        rows = conn.execute("""
            SELECT * FROM policies 
            WHERE date(created_at) = date(?)
            ORDER BY created_at DESC
        """, (date_str,)).fetchall()
        return [dict(row) for row in rows]

def get_policies_by_date_range(start_date: str, end_date: str) -> List[Dict[str, Any]]:
    with get_db() as conn:
        rows = conn.execute("""
            SELECT * FROM policies 
            WHERE date(created_at) BETWEEN date(?) AND date(?)
            ORDER BY created_at DESC
        """, (start_date, end_date)).fetchall()
        return [dict(row) for row in rows]

# ==================== AI ì—”ì§„ (AI Engine) ====================

def parse_json_response(text: str) -> Optional[Dict]:
    text = text.strip()
    if text.startswith("```"):
        text = text.replace("```json", "").replace("```", "").strip()
    try:
        return json.loads(text)
    except:
        return None

def generate_policy_analysis(
    title: str,
    category: str,
    target_audience: str,
    description: str,
    keywords: str = "",
    constraints: str = "",
    model: str = "gpt-4o"
) -> Tuple[Optional[Dict], str]:
    
    prompt = f"""
ë‹¹ì‹ ì€ ì •ì„¸ë‹´ ì •ì±… ìë™í™” ì‹œìŠ¤í…œì˜ AIì…ë‹ˆë‹¤.
ì •ì±…ì˜ ê¸°íšë¶€í„° ì‹¤í–‰, í™ë³´, ì„±ê³¼ê´€ë¦¬ê¹Œì§€ ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì„¤ê³„í•©ë‹ˆë‹¤.

[ì…ë ¥ ì •ë³´]
ì •ì±… ì œëª©: {title}
ì •ì±… ì¹´í…Œê³ ë¦¬: {category}
ëŒ€ìƒ: {target_audience}
ì •ì±… ì„¤ëª…: {description}
ê°•ì¡° í‚¤ì›Œë“œ: {keywords}
ì œì•½ ì¡°ê±´: {constraints}

[ì¶œë ¥ ê·œì¹™]
- ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥
- í•œêµ­ í˜„ì‹¤ì— ë§ëŠ” ì‹¤í–‰ ê°€ëŠ¥í•œ ë‚´ìš©
- ê³¼ì¥ ê¸ˆì§€, ì¸¡ì • ê°€ëŠ¥í•œ ì§€í‘œ ì‚¬ìš©
- ëŒ€ìƒì— ë§ëŠ” í†¤ê³¼ ë©”ì‹œì§€

[JSON ìŠ¤í‚¤ë§ˆ]
{{
  "policy_planning": {{
    "objective": "ì •ì±… ëª©í‘œ (3-5ë¬¸ì¥)",
    "target_analysis": "ëŒ€ìƒ ë¶„ì„ (ë‹ˆì¦ˆ, íŠ¹ì„±, ì ‘ê·¼ë²• 3-5ë¬¸ì¥)",
    "key_strategies": ["í•µì‹¬ ì „ëµ 5-8ê°œ"],
    "expected_outcomes": ["ê¸°ëŒ€ íš¨ê³¼ 5-7ê°œ"],
    "timeline": {{
      "preparation": "ì¤€ë¹„ ë‹¨ê³„ ë‚´ìš©",
      "pilot": "ì‹œë²” ìš´ì˜ ë‚´ìš©",
      "expansion": "í™•ëŒ€ ì ìš© ë‚´ìš©"
    }}
  }},
  
  "execution_plan": {{
    "action_items": [
      {{
        "phase": "ë‹¨ê³„ëª…",
        "action": "ì‹¤í–‰ ë‚´ìš©",
        "responsible": "ë‹´ë‹¹ ì£¼ì²´",
        "timeline": "ì†Œìš” ê¸°ê°„"
      }}
    ],
    "resources_needed": {{
      "budget_range": "ì˜ˆì‚° ë²”ìœ„ (êµ¬ì²´ì  ê¸ˆì•¡ ëŒ€ì‹  ë²”ì£¼)",
      "personnel": "í•„ìš” ì¸ë ¥",
      "infrastructure": "í•„ìš” ì¸í”„ë¼"
    }},
    "risk_management": [
      {{
        "risk": "ë¦¬ìŠ¤í¬ í•­ëª©",
        "impact": "ì˜í–¥ë„",
        "mitigation": "ì™„í™” ë°©ì•ˆ"
      }}
    ]
  }},
  
  "communication_strategy": {{
    "key_messages": ["í•µì‹¬ ë©”ì‹œì§€ 5-8ê°œ"],
    "channels": [
      {{
        "channel": "ì±„ë„ëª…",
        "content_type": "ì½˜í…ì¸  í˜•ì‹",
        "frequency": "ë°œí–‰ ì£¼ê¸°"
      }}
    ],
    "target_specific_messages": {{
      "citizens": "ì‹œë¯¼ ëŒ€ìƒ ë©”ì‹œì§€",
      "youth": "ì²­ë…„ ëŒ€ìƒ ë©”ì‹œì§€",
      "elderly": "ë…¸ì¸ ëŒ€ìƒ ë©”ì‹œì§€",
      "parents": "í•™ë¶€ëª¨ ëŒ€ìƒ ë©”ì‹œì§€"
    }}
  }},
  
  "content_briefs": {{
    "image_brief_1": {{
      "concept": "ì´ë¯¸ì§€ ì»¨ì…‰ (5-7ë¬¸ì¥)",
      "scene_description": "ì¥ë©´ ìƒì„¸ ë¬˜ì‚¬ (10-15ë¬¸ì¥)",
      "visual_style": "ë¹„ì£¼ì–¼ ìŠ¤íƒ€ì¼ (ì´¬ì˜ ê¸°ë²•, ì¡°ëª…, ìƒ‰ê°)",
      "key_message": "ì „ë‹¬í•  í•µì‹¬ ë©”ì‹œì§€"
    }},
    "image_brief_2": {{
      "concept": "ì´ë¯¸ì§€ ì»¨ì…‰ (5-7ë¬¸ì¥)",
      "scene_description": "ì¥ë©´ ìƒì„¸ ë¬˜ì‚¬ (10-15ë¬¸ì¥)",
      "visual_style": "ë¹„ì£¼ì–¼ ìŠ¤íƒ€ì¼ (ì´¬ì˜ ê¸°ë²•, ì¡°ëª…, ìƒ‰ê°)",
      "key_message": "ì „ë‹¬í•  í•µì‹¬ ë©”ì‹œì§€"
    }},
    "video_brief": {{
      "duration": "ì˜ìƒ ê¸¸ì´",
      "narrative_arc": "ìŠ¤í† ë¦¬ êµ¬ì¡° (5-8ë¬¸ì¥)",
      "scenes": [
        {{
          "timestamp": "ì‹œê°„ëŒ€",
          "scene": "ì¥ë©´ ë‚´ìš©",
          "visuals": "ë¹„ì£¼ì–¼ ìš”ì†Œ",
          "audio": "ì˜¤ë””ì˜¤ (ë‚´ë ˆì´ì…˜/ìŒì•…/íš¨ê³¼ìŒ)",
          "message": "ì „ë‹¬ ë©”ì‹œì§€"
        }}
      ],
      "style_guide": "ì˜ìƒ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ",
      "call_to_action": "í–‰ë™ ìœ ë„ ë¬¸êµ¬"
    }}
  }},
  
  "marketing_materials": {{
    "slogan": "ìŠ¬ë¡œê±´ (20-30ì)",
    "tagline": "íƒœê·¸ë¼ì¸ (40-60ì)",
    "elevator_pitch": "ì—˜ë¦¬ë² ì´í„° í”¼ì¹˜ (150-200ì)",
    "press_release": "ë³´ë„ìë£Œ í˜•ì‹ (300-500ì)",
    "social_media_posts": [
      {{
        "platform": "í”Œë«í¼",
        "content": "ê²Œì‹œë¬¼ ë‚´ìš©",
        "hashtags": ["í•´ì‹œíƒœê·¸"]
      }}
    ],
    "faq": [
      {{
        "question": "ìì£¼ ë¬»ëŠ” ì§ˆë¬¸",
        "answer": "ë‹µë³€"
      }}
    ]
  }},
  
  "performance_metrics": {{
    "kpi_framework": [
      {{
        "category": "ì§€í‘œ ì¹´í…Œê³ ë¦¬",
        "metric": "ì¸¡ì • í•­ëª©",
        "measurement_method": "ì¸¡ì • ë°©ë²•",
        "target_range": "ëª©í‘œ ë²”ìœ„ (êµ¬ê°„/ì¶”ì´)",
        "data_source": "ë°ì´í„° ì¶œì²˜"
      }}
    ],
    "success_criteria": ["ì„±ê³µ ê¸°ì¤€ 5-7ê°œ"],
    "monitoring_plan": {{
      "daily": "ì¼ê°„ ëª¨ë‹ˆí„°ë§ í•­ëª©",
      "weekly": "ì£¼ê°„ ëª¨ë‹ˆí„°ë§ í•­ëª©",
      "monthly": "ì›”ê°„ ëª¨ë‹ˆí„°ë§ í•­ëª©"
    }},
    "improvement_triggers": ["ê°œì„ ì´ í•„ìš”í•œ ì‹œì ì„ ì•Œë¦¬ëŠ” ì§€í‘œ 5-7ê°œ"]
  }},
  
  "stakeholder_management": {{
    "stakeholders": [
      {{
        "group": "ì´í•´ê´€ê³„ì ê·¸ë£¹",
        "interests": "ê´€ì‹¬ì‚¬",
        "engagement_strategy": "ì†Œí†µ ì „ëµ"
      }}
    ],
    "objection_handling": [
      {{
        "objection": "ì˜ˆìƒ ë°˜ëŒ€ ì˜ê²¬",
        "response": "ëŒ€ì‘ ë…¼ë¦¬"
      }}
    ]
  }}
}}

ìœ„ ìŠ¤í‚¤ë§ˆë¥¼ ì •í™•íˆ ë”°ë¼ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.
"""

    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì •ì±… ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•­ìƒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=4000
        )
        
        raw_text = response.choices[0].message.content
        parsed_data = parse_json_response(raw_text)
        
        if parsed_data:
            return parsed_data, raw_text
        
        # JSON íŒŒì‹± ì‹¤íŒ¨ì‹œ ì¬ì‹œë„
        retry_prompt = f"""
ì´ì „ ì‘ë‹µì´ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.
ì•„ë˜ ë‚´ìš©ì„ ì™„ë²½í•œ JSONìœ¼ë¡œ ë‹¤ì‹œ ì¶œë ¥í•´ì£¼ì„¸ìš”.

{raw_text}
"""
        
        retry_response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•©ë‹ˆë‹¤."},
                {"role": "user", "content": retry_prompt}
            ],
            temperature=0.3,
            max_tokens=4000
        )
        
        retry_text = retry_response.choices[0].message.content
        retry_parsed = parse_json_response(retry_text)
        
        return retry_parsed, retry_text
        
    except Exception as e:
        return None, f"Error: {str(e)}"

def generate_image_prompt(brief: Dict[str, Any], style_override: str = "") -> str:
    concept = brief.get("concept", "")
    scene = brief.get("scene_description", "")
    style = brief.get("visual_style", "")
    message = brief.get("key_message", "")
    
    base_style = style_override if style_override else DEFAULT_IMAGE_STYLE
    
    prompt = f"""
{concept}

Scene description: {scene}

Visual style: {style}

{base_style}

Key message to convey: {message}

Important: Create realistic Korean people with natural, undistorted facial features.
No text or writing should appear anywhere in the image.
Focus on authentic Korean urban/suburban environment and genuine human expressions.
"""
    
    return prompt.strip()

def generate_video_prompts_3styles(brief: Dict[str, Any]) -> Dict[str, str]:
    """10ì´ˆ ì˜ìƒ 3ê°€ì§€ ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    
    narrative = brief.get("narrative_arc", "")
    cta = brief.get("call_to_action", "")
    
    base_context = f"""
Duration: 10 seconds
Location: Modern South Korea
Language: Korean subtitles only
No English text visible
"""
    
    # ìŠ¤íƒ€ì¼ 1: ë‹¤íë©˜í„°ë¦¬
    style1 = f"""
[ìŠ¤íƒ€ì¼ 1: ë‹¤íë©˜í„°ë¦¬ ë¦¬ì–¼ë¦¬ì¦˜]

{base_context}

Visual Style:
- Handheld camera feel, natural movements
- Realistic lighting, documentary aesthetic
- Authentic Korean street scenes and people
- Observational approach, fly-on-the-wall style
- Natural color grading with slight desaturation

Camera:
- Medium shots and close-ups
- Slight camera shake for realism
- Follow subjects naturally

Audio:
- Natural ambient sounds (traffic, voices, city sounds)
- Minimal background music
- Natural Korean dialogue or voice-over

Narrative: {narrative}

Mood: Authentic, grounded, trustworthy
Pacing: Steady, observational
Final Message: {cta}

Technical: 24fps, cinematic aspect ratio, professional documentary style
"""
    
    # ìŠ¤íƒ€ì¼ 2: ì‹œë„¤ë§ˆí‹±
    style2 = f"""
[ìŠ¤íƒ€ì¼ 2: ì‹œë„¤ë§ˆí‹± ë“œë¼ë§ˆ]

{base_context}

Visual Style:
- Smooth cinematic camera movements (gimbal/slider)
- Dramatic lighting with warm and cool tones
- Korean urban landscape with cinematic composition
- Establishing shots of Seoul skyline or modern architecture
- Rich color grading inspired by Korean cinema

Camera:
- Wide establishing shots
- Slow push-ins and reveals
- Overhead/drone shots of Korean cityscape
- Smooth tracking shots

Audio:
- Emotional background music (orchestral or modern Korean OST style)
- Carefully designed sound effects
- Polished voice-over narration

Narrative: {narrative}

Mood: Inspiring, emotional, aspirational
Pacing: Dynamic with emotional beats
Final Message: {cta}

Technical: 24fps, anamorphic feel, cinematic color grade
"""
    
    # ìŠ¤íƒ€ì¼ 3: ëª¨ë˜ ë‹¤ì´ë‚´ë¯¹
    style3 = f"""
[ìŠ¤íƒ€ì¼ 3: ëª¨ë˜ ë‹¤ì´ë‚´ë¯¹]

{base_context}

Visual Style:
- Fast-paced dynamic cuts
- Modern Korean lifestyle and technology
- Bright, energetic visuals
- Clean, contemporary aesthetic
- Vibrant color grading with saturated tones

Camera:
- Quick cuts between multiple angles
- Time-lapse of Korean city life
- Dynamic camera movements
- Close-ups on details and faces
- Match cuts for visual rhythm

Audio:
- Upbeat modern Korean music
- Rhythmic sound design
- Quick voice-over or on-screen Korean text animations
- Sync with visual cuts

Narrative: {narrative}

Mood: Energetic, modern, forward-thinking
Pacing: Fast, rhythmic, attention-grabbing
Final Message: {cta}

Technical: 30fps or 60fps slow-motion elements, high contrast, vibrant colors
"""
    
    return {
        "documentary": style1,
        "cinematic": style2,
        "modern_dynamic": style3
    }

# ==================== ì´ë¯¸ì§€ ìƒì„± (Image Generator) ====================

def generate_policy_image(
    brief: dict,
    size: str = "1024x1024",
    quality: str = "standard"
) -> Optional[Tuple[Image.Image, bytes]]:
    """ì •ì±… ì´ë¯¸ì§€ ìƒì„± (brief ê¸°ë°˜)"""
    
    prompt = generate_image_prompt(brief)
    
    try:
        response = client.images.generate(
            model="dall-e-3",
            prompt=prompt,
            size=size,
            quality=quality,
            n=1,
            response_format="b64_json"
        )
        
        if response.data and len(response.data) > 0:
            b64_data = response.data[0].b64_json
            image_bytes = base64.b64decode(b64_data)
            image = Image.open(BytesIO(image_bytes))
            return (image, image_bytes)
        
        return None
        
    except Exception as e:
        st.error(f"ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        return None

def batch_generate_images(prompts: List[str], size: str = "1024x1024", quality: str = "standard") -> List[Tuple[Image.Image, bytes]]:
    """ì—¬ëŸ¬ ì´ë¯¸ì§€ ìˆœì°¨ ìƒì„±"""
    results = []
    for prompt in prompts:
        try:
            response = client.images.generate(
                model="dall-e-3",
                prompt=prompt,
                size=size,
                quality=quality,
                n=1,
                response_format="b64_json"
            )
            
            if response.data and len(response.data) > 0:
                b64_data = response.data[0].b64_json
                image_bytes = base64.b64decode(b64_data)
                image = Image.open(BytesIO(image_bytes))
                results.append((image, image_bytes))
        except Exception as e:
            st.error(f"ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            continue
    
    return results

# ==================== PDF/ZIP ë‚´ë³´ë‚´ê¸° (Export Manager) ====================

def create_pdf_report(policy: Dict[str, Any], analysis: Dict[str, Any], images: List[bytes] = None, video_prompts: List[str] = None) -> bytes:
    """í•œê¸€ ì •ì±… ë³´ê³ ì„œ PDF ìƒì„± - AI ë¶„ì„ 9ê°œ í•­ëª© ì „ì²´ í¬í•¨"""
    
    buffer = BytesIO()
    c = canvas.Canvas(buffer, pagesize=A4)
    width, height = A4
    
    # í•œê¸€ í°íŠ¸
    try:
        pdfmetrics.registerFont(UnicodeCIDFont('HYSMyeongJo-Medium'))
        font_name = 'HYSMyeongJo-Medium'
    except:
        font_name = 'Helvetica'
    
    def new_page():
        c.showPage()
        return height - 50
    
    def add_heading(y, text, size=14):
        if y < 100:
            y = new_page()
        c.setFont(font_name, size)
        c.drawString(50, y, text[:90])
        return y - (size + 15)
    
    def add_text(y, text, size=10, indent=60):
        if y < 80:
            y = new_page()
        c.setFont(font_name, size)
        max_len = 85 if indent == 60 else 90
        lines = [text[i:i+max_len] for i in range(0, min(len(text), 400), max_len)]
        for line in lines[:10]:
            if y < 60:
                y = new_page()
                c.setFont(font_name, size)
            c.drawString(indent, y, line)
            y -= (size + 4)
        return y - 5
    
    y = height - 50
    
    # í‘œì§€
    c.setFont(font_name, 24)
    c.drawString(50, y, "ì •ì±… ë³´ê³ ì„œ")
    y -= 50
    c.setFont(font_name, 14)
    c.drawString(50, y, f"ì œëª©: {policy.get('title', '')[:50]}")
    y -= 25
    c.setFont(font_name, 11)
    c.drawString(50, y, f"ì¹´í…Œê³ ë¦¬: {policy.get('category', '')[:60]}")
    y -= 20
    c.drawString(50, y, f"ëŒ€ìƒ: {policy.get('target_audience', '')}")
    y -= 20
    c.drawString(50, y, f"ìƒì„±ì¼: {policy.get('created_at', '')}")
    
    if not analysis:
        c.save()
        buffer.seek(0)
        return buffer.read()
    
    y = new_page()
    
    # ===== 1. ì •ì±… ê¸°íš =====
    y = add_heading(y, "1. ì •ì±… ê¸°íš", 16)
    if "policy_planning" in analysis:
        planning = analysis["policy_planning"]
        
        if planning.get("objective"):
            y = add_text(y, f"[ëª©í‘œ] {planning['objective']}", 10, 60)
        
        if planning.get("target_analysis"):
            y = add_text(y, f"[ëŒ€ìƒ ë¶„ì„] {planning['target_analysis']}", 10, 60)
        
        if planning.get("key_strategies"):
            y = add_text(y, "[í•µì‹¬ ì „ëµ]", 11, 60)
            for idx, s in enumerate(planning["key_strategies"][:8], 1):
                y = add_text(y, f"{idx}. {s}", 10, 70)
        
        if planning.get("expected_outcomes"):
            y = add_text(y, "[ê¸°ëŒ€ íš¨ê³¼]", 11, 60)
            for o in planning["expected_outcomes"][:5]:
                y = add_text(y, f"â€¢ {o}", 10, 70)
    
    y -= 15
    
    # ===== 2. ì‹¤í–‰ ê³„íš =====
    if y < 150:
        y = new_page()
    y = add_heading(y, "2. ì‹¤í–‰ ê³„íš", 16)
    if "execution_plan" in analysis:
        execution = analysis["execution_plan"]
        
        if execution.get("action_items"):
            y = add_text(y, "[ì‹¤í–‰ í•­ëª©]", 11, 60)
            for idx, item in enumerate(execution["action_items"][:8], 1):
                y = add_text(y, f"{idx}. {item.get('action', '')}", 10, 70)
        
        if execution.get("resources_needed"):
            res = execution["resources_needed"]
            y = add_text(y, "[í•„ìš” ìì›]", 11, 60)
            if res.get("budget_range"):
                y = add_text(y, f"ì˜ˆì‚°: {res['budget_range']}", 10, 70)
            if res.get("personnel"):
                y = add_text(y, f"ì¸ë ¥: {res['personnel']}", 10, 70)
    
    y -= 15
    
    # ===== 3. ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì „ëµ =====
    if y < 150:
        y = new_page()
    y = add_heading(y, "3. ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì „ëµ", 16)
    if "communication_strategy" in analysis:
        comm = analysis["communication_strategy"]
        
        if comm.get("key_messages"):
            y = add_text(y, "[í•µì‹¬ ë©”ì‹œì§€]", 11, 60)
            for idx, msg in enumerate(comm["key_messages"][:8], 1):
                y = add_text(y, f"{idx}. {msg}", 10, 70)
        
        if comm.get("channels"):
            y = add_text(y, "[ì±„ë„ ì „ëµ]", 11, 60)
            for ch in comm["channels"][:5]:
                y = add_text(y, f"â€¢ {ch.get('channel', '')}: {ch.get('content_type', '')}", 10, 70)
    
    y -= 15
    
    # ===== 4. ì½˜í…ì¸  ì œì‘ ë¸Œë¦¬í”„ =====
    if y < 150:
        y = new_page()
    y = add_heading(y, "4. ì½˜í…ì¸  ì œì‘ ë¸Œë¦¬í”„", 16)
    if "content_briefs" in analysis:
        briefs = analysis["content_briefs"]
        
        if "image_brief_1" in briefs:
            b1 = briefs["image_brief_1"]
            y = add_text(y, "[ì´ë¯¸ì§€ ë¸Œë¦¬í”„ 1]", 11, 60)
            y = add_text(y, f"ì»¨ì…‰: {b1.get('concept', '')}", 10, 70)
            y = add_text(y, f"ì¥ë©´: {b1.get('scene_description', '')}", 10, 70)
        
        if "image_brief_2" in briefs:
            b2 = briefs["image_brief_2"]
            y = add_text(y, "[ì´ë¯¸ì§€ ë¸Œë¦¬í”„ 2]", 11, 60)
            y = add_text(y, f"ì»¨ì…‰: {b2.get('concept', '')}", 10, 70)
            y = add_text(y, f"ì¥ë©´: {b2.get('scene_description', '')}", 10, 70)
        
        if "video_brief" in briefs:
            vb = briefs["video_brief"]
            y = add_text(y, "[ì˜ìƒ ë¸Œë¦¬í”„]", 11, 60)
            y = add_text(y, f"ìŠ¤í† ë¦¬: {vb.get('narrative_arc', '')}", 10, 70)
    
    y -= 15
    
    # ===== 5. ë§ˆì¼€íŒ… ìë£Œ =====
    if y < 150:
        y = new_page()
    y = add_heading(y, "5. ë§ˆì¼€íŒ… ìë£Œ", 16)
    if "marketing_materials" in analysis:
        mk = analysis["marketing_materials"]
        
        if mk.get("slogan"):
            y = add_text(y, f"[ìŠ¬ë¡œê±´] {mk['slogan']}", 11, 60)
        
        if mk.get("tagline"):
            y = add_text(y, f"[íƒœê·¸ë¼ì¸] {mk['tagline']}", 10, 60)
        
        if mk.get("elevator_pitch"):
            y = add_text(y, f"[ì—˜ë¦¬ë² ì´í„° í”¼ì¹˜] {mk['elevator_pitch']}", 10, 60)
        
        if mk.get("social_media_posts"):
            y = add_text(y, "[ì†Œì…œë¯¸ë””ì–´ ì½˜í…ì¸ ]", 11, 60)
            for idx, post in enumerate(mk["social_media_posts"][:5], 1):
                y = add_text(y, f"{idx}. {post.get('platform', '')}: {post.get('content', '')}", 10, 70)
    
    y -= 15
    
    # ===== 6. ì„±ê³¼ ì§€í‘œ (KPI) =====
    if y < 150:
        y = new_page()
    y = add_heading(y, "6. ì„±ê³¼ ì§€í‘œ (KPI)", 16)
    if "performance_metrics" in analysis:
        metrics = analysis["performance_metrics"]
        
        if metrics.get("kpi_framework"):
            y = add_text(y, "[KPI í”„ë ˆì„ì›Œí¬]", 11, 60)
            for idx, kpi in enumerate(metrics["kpi_framework"][:8], 1):
                y = add_text(y, f"{idx}. {kpi.get('metric', '')}", 10, 70)
                if kpi.get("target_range"):
                    y = add_text(y, f"   ëª©í‘œ: {kpi['target_range']}", 9, 75)
        
        if metrics.get("success_criteria"):
            y = add_text(y, "[ì„±ê³µ ê¸°ì¤€]", 11, 60)
            for sc in metrics["success_criteria"][:5]:
                y = add_text(y, f"â€¢ {sc}", 10, 70)
    
    y -= 15
    
    # ===== 7. ì´í•´ê´€ê³„ì ê´€ë¦¬ =====
    if y < 150:
        y = new_page()
    y = add_heading(y, "7. ì´í•´ê´€ê³„ì ê´€ë¦¬", 16)
    if "stakeholder_management" in analysis:
        sh = analysis["stakeholder_management"]
        
        if sh.get("stakeholders"):
            y = add_text(y, "[ì´í•´ê´€ê³„ì ë¶„ì„]", 11, 60)
            for idx, s in enumerate(sh["stakeholders"][:6], 1):
                y = add_text(y, f"{idx}. {s.get('group', '')}: {s.get('interests', '')}", 10, 70)
        
        if sh.get("objection_handling"):
            y = add_text(y, "[ë°˜ëŒ€ ì˜ê²¬ ëŒ€ì‘]", 11, 60)
            for obj in sh["objection_handling"][:4]:
                y = add_text(y, f"â€¢ ë°˜ëŒ€: {obj.get('objection', '')}", 10, 70)
                y = add_text(y, f"  ëŒ€ì‘: {obj.get('response', '')}", 9, 75)
    
    y -= 15
    
    # ===== 8. ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ =====
    if images:
        if y < 150:
            y = new_page()
        y = add_heading(y, "8. ìƒì„±ëœ ì´ë¯¸ì§€", 16)
        
        for idx, img_bytes in enumerate(images[:4], 1):
            if y < 250:
                y = new_page()
            try:
                img = ImageReader(BytesIO(img_bytes))
                c.drawImage(img, 50, y - 200, width=450, height=200, preserveAspectRatio=True)
                y -= 220
                c.setFont(font_name, 10)
                c.drawString(50, y, f"ì´ë¯¸ì§€ {idx}")
                y -= 30
            except:
                pass
    
    # ===== 9. ì˜ìƒ í”„ë¡¬í”„íŠ¸ =====
    if video_prompts:
        y = new_page()
        y = add_heading(y, "9. ì˜ìƒ í”„ë¡¬í”„íŠ¸", 16)
        
        for idx, prompt in enumerate(video_prompts[:9], 1):
            if y < 150:
                y = new_page()
            y = add_text(y, f"[ì˜ìƒ {idx}]", 11, 60)
            y = add_text(y, prompt[:600], 9, 70)
            y -= 15
    
    c.save()
    buffer.seek(0)
    return buffer.read()

def create_zip_export(
    policy: Dict[str, Any],
    analysis: Dict[str, Any],
    images: List[bytes] = None,
    video_prompts: List[str] = None,
    pdf_bytes: bytes = None
) -> bytes:
    """ëª¨ë“  ìë£Œë¥¼ ZIPìœ¼ë¡œ ì••ì¶• (PDF í¬í•¨)"""
    
    buffer = BytesIO()
    
    with ZipFile(buffer, 'w') as zipf:
        # PDF ë³´ê³ ì„œ (ìµœìš°ì„ )
        if pdf_bytes:
            zipf.writestr("ì •ì±…_ë³´ê³ ì„œ_ì „ì²´.pdf", pdf_bytes)
        
        # ì •ì±… ì •ë³´
        zipf.writestr("policy_info.json", json.dumps(policy, ensure_ascii=False, indent=2))
        
        # AI ë¶„ì„ ê²°ê³¼
        zipf.writestr("analysis_full.json", json.dumps(analysis, ensure_ascii=False, indent=2))
        
        # ì´ë¯¸ì§€
        if images:
            for idx, img_bytes in enumerate(images, 1):
                zipf.writestr(f"images/image_{idx}.png", img_bytes)
        
        # ì˜ìƒ í”„ë¡¬í”„íŠ¸
        if video_prompts:
            for idx, prompt in enumerate(video_prompts, 1):
                zipf.writestr(f"video_prompts/prompt_{idx}.txt", prompt)
        
        # README
        readme = f"""
ì •ì„¸ë‹´ ì •ì±… í”„ë¡œê·¸ë¨ - ê²°ê³¼ë¬¼ íŒ¨í‚¤ì§€

ì •ì±… ì œëª©: {policy['title']}
ìƒì„±ì¼: {policy['created_at']}

í¬í•¨ ë‚´ìš©:
- ì •ì±…_ë³´ê³ ì„œ_ì „ì²´.pdf: AI ë¶„ì„ 7ê°œ ì„¹ì…˜ + ì´ë¯¸ì§€ + ì˜ìƒ í”„ë¡¬í”„íŠ¸ ì „ì²´ (PDF)
- policy_info.json: ì •ì±… ê¸°ë³¸ ì •ë³´
- analysis_full.json: AI ë¶„ì„ ì „ì²´ ê²°ê³¼ (JSON)
- images/: ìƒì„±ëœ ì´ë¯¸ì§€
- video_prompts/: ì˜ìƒ ì œì‘ í”„ë¡¬í”„íŠ¸

ì‚¬ìš© ë°©ë²•:
1. ì •ì±…_ë³´ê³ ì„œ_ì „ì²´.pdfë¥¼ ì—´ì–´ ì „ì²´ ë‚´ìš© í™•ì¸ (ê¶Œì¥)
2. analysis_full.jsonì„ ì—´ì–´ JSON í˜•íƒœë¡œ í™•ì¸
3. images í´ë”ì˜ ì´ë¯¸ì§€ í™œìš©
4. video_promptsì˜ í”„ë¡¬í”„íŠ¸ë¥¼ Sora, Runway, Pika ë“±ì— ì…ë ¥
"""
        zipf.writestr("README.txt", readme)
    
    buffer.seek(0)
    return buffer.read()

# ==================== Streamlit UI ====================

st.set_page_config(
    page_title="ì •ì„¸ë‹´ ì •ì±… í”„ë¡œê·¸ë¨",
    page_icon="ğŸ›ï¸",
    layout="wide",
    initial_sidebar_state="collapsed"  # ëª¨ë°”ì¼ ìµœì í™”: ê¸°ë³¸ ì¶•ì†Œ
)

st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #666;
        text-align: center;
        margin-bottom: 2rem;
    }
    /* ì‚¬ì´ë“œë°” í™”ì‚´í‘œ ê³ ì • */
    [data-testid="collapsedControl"] {
        position: sticky !important;
        top: 0 !important;
        z-index: 999 !important;
    }
    /* ëª¨ë°”ì¼ ìµœì í™” */
    @media (max-width: 768px) {
        .main-header {
            font-size: 1.8rem;
        }
        .sub-header {
            font-size: 1rem;
        }
    }
</style>
""", unsafe_allow_html=True)

def init_session_state():
    defaults = {
        "current_policy_id": None,
        "current_analysis": None,
        "generated_images": [],
        "video_prompts_3styles": [],
        "workflow_step": "ê¸°íš",
        "show_results": False,
        "selected_category": "",
        "temp_selection": "",
        "active_tab": 0  # íƒ­ ì „í™˜ìš©
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

init_session_state()
init_database()

st.markdown('<div class="main-header">ğŸ›ï¸ ì •ì„¸ë‹´ ì •ì±… í”„ë¡œê·¸ë¨</div>', unsafe_allow_html=True)
st.markdown('<div class="sub-header">ì •ì±… ê¸°íšÂ·ì‹¤í–‰Â·í™ë³´Â·ì„±ê³¼ê´€ë¦¬ ìë™í™” ì‹œìŠ¤í…œ</div>', unsafe_allow_html=True)

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.markdown("### ğŸ“‹ í”„ë¡œì„¸ìŠ¤ ë‹¨ê³„ (í´ë¦­í•˜ì—¬ ì´ë™)")
    
    step_mapping = {
        "ê¸°íš": 0,      # ì •ì±… ì…ë ¥ íƒ­
        "ì‹¤í–‰": 1,      # AI ë¶„ì„ ìƒì„± íƒ­
        "í™ë³´": 2,      # ì´ë¯¸ì§€ ìƒì„± íƒ­
        "ì„±ê³¼ê´€ë¦¬": 4   # ê²°ê³¼ ë° ë‚´ë³´ë‚´ê¸° íƒ­
    }
    
    steps = ["ê¸°íš", "ì‹¤í–‰", "í™ë³´", "ì„±ê³¼ê´€ë¦¬"]
    current_step_idx = steps.index(st.session_state.workflow_step)
    
    for idx, step in enumerate(steps):
        if idx < current_step_idx:
            if st.button(f"âœ… {step}", key=f"step_{step}", use_container_width=True):
                st.session_state.active_tab = step_mapping[step]
                st.rerun()
        elif idx == current_step_idx:
            if st.button(f"â–¶ï¸ {step} (í˜„ì¬)", key=f"step_{step}", use_container_width=True, type="primary"):
                st.session_state.active_tab = step_mapping[step]
                st.rerun()
        else:
            if st.button(f"â¸ï¸ {step}", key=f"step_{step}", use_container_width=True, disabled=False):
                st.session_state.active_tab = step_mapping[step]
                st.rerun()
    
    st.divider()
    
    st.markdown("### ğŸ“… ë‚ ì§œë³„ ì •ì±… ê²€ìƒ‰")
    
    search_type = st.radio("ê²€ìƒ‰ ë°©ì‹", ["ì „ì²´ ë³´ê¸°", "ë‚ ì§œ ì„ íƒ", "ë‚ ì§œ ë²”ìœ„"], horizontal=True)
    
    if search_type == "ë‚ ì§œ ì„ íƒ":
        selected_date = st.date_input("ë‚ ì§œ ì„ íƒ", value=date.today())
        policies = get_policies_by_date(selected_date.strftime("%Y-%m-%d"))
        st.caption(f"{selected_date.strftime('%Y-%m-%d')} ì •ì±… {len(policies)}ê±´")
    elif search_type == "ë‚ ì§œ ë²”ìœ„":
        col1, col2 = st.columns(2)
        with col1:
            start_date = st.date_input("ì‹œì‘", value=date.today())
        with col2:
            end_date = st.date_input("ì¢…ë£Œ", value=date.today())
        policies = get_policies_by_date_range(
            start_date.strftime("%Y-%m-%d"),
            end_date.strftime("%Y-%m-%d")
        )
        st.caption(f"{len(policies)}ê±´ ë°œê²¬")
    else:
        policies = get_all_policies(limit=20)
        st.caption(f"ìµœê·¼ {len(policies)}ê±´")
    
    st.markdown("### ğŸ—‚ï¸ ì €ì¥ëœ ì •ì±…")
    
    if policies:
        for policy in policies:
            with st.expander(f"{policy['title'][:20]}..."):
                st.write(f"ğŸ“… {policy['created_at'][:10]}")
                st.write(f"ì¹´í…Œê³ ë¦¬: {policy['category']}")
                st.write(f"ëŒ€ìƒ: {policy['target_audience']}")
                if st.button("ë¶ˆëŸ¬ì˜¤ê¸°", key=f"load_{policy['id']}"):
                    st.session_state.current_policy_id = policy['id']
                    contents = get_policy_contents(policy['id'])
                    if contents:
                        for content in contents:
                            if content['content_type'] == 'analysis':
                                st.session_state.current_analysis = content['content_data']
                    
                    media = get_generated_media(policy['id'])
                    st.session_state.generated_images = []
                    
                    for m in media:
                        if m['media_type'] == 'image' and m['media_data']:
                            img = Image.open(BytesIO(m['media_data']))
                            st.session_state.generated_images.append({
                                "image": img,
                                "bytes": m['media_data'],
                                "brief": "loaded"
                            })
                    
                    st.success(f"âœ… ì •ì±… ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ!")
                    st.rerun()
    else:
        st.info("ì €ì¥ëœ ì •ì±…ì´ ì—†ìŠµë‹ˆë‹¤")
    
    st.divider()
    
    if st.button("ğŸ†• ìƒˆ ì •ì±… ì‹œì‘", use_container_width=True):
        for key in ["current_policy_id", "current_analysis", "generated_images", "video_prompts_3styles", "selected_category", "temp_selection"]:
            st.session_state[key] = [] if "images" in key or "prompts" in key else ("" if "category" in key or "selection" in key else None)
        st.session_state.workflow_step = "ê¸°íš"
        st.session_state.show_results = False
        st.rerun()

# ë©”ì¸ íƒ­
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "ğŸ“ ì •ì±… ì…ë ¥",
    "ğŸ¤– AI ë¶„ì„ ìƒì„±",
    "ğŸ–¼ï¸ ì´ë¯¸ì§€ ìƒì„±",
    "ğŸ¬ ì˜ìƒ í”„ë¡¬í”„íŠ¸",
    "ğŸ“Š ê²°ê³¼ ë° ë‚´ë³´ë‚´ê¸°"
])

with tab1:
    st.markdown("### 1ï¸âƒ£ ì •ì±… ê¸°ë³¸ ì •ë³´ ì…ë ¥")
    
    col1, col2 = st.columns(2)
    
    with col1:
        policy_title = st.text_input(
            "ì •ì±… ì œëª© *",
            placeholder="ì˜ˆ: ë„ì‹œ ëŒ€ê¸°ì§ˆ ì‹¤ì‹œê°„ ê´€ë¦¬ ì •ì±…",
            help="ì •ì±…ì˜ í•µì‹¬ì„ ë‹´ì€ ëª…í™•í•œ ì œëª©"
        )
        
        # ì¹´í…Œê³ ë¦¬ ë°ì´í„°ë² ì´ìŠ¤
        category_database = {
            "í™˜ê²½": {
                "ëŒ€ê¸°ì§ˆ": ["ë¯¸ì„¸ë¨¼ì§€ ì €ê°", "ëŒ€ê¸°ì˜¤ì—¼ ê´€ë¦¬", "ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§", "ë°°ì¶œê°€ìŠ¤ ê·œì œ", "ëŒ€ê¸°ì§ˆ ì˜ˆë³´", "ë¯¸ì„¸ë¨¼ì§€ ì‹ í˜¸ë“±", "í´ë¦°ì¡´ ì¡°ì„±", "ëŒ€ê¸°ì˜¤ì—¼ ì´ëŸ‰ì œ", "ë°°ì¶œê¶Œ ê±°ë˜", "ì¹œí™˜ê²½ì°¨ ë³´ê¸‰", "ê²½ìœ ì°¨ ì €ê°", "ê³µì¥ ë°°ì¶œ ê´€ë¦¬"],
                "ìˆ˜ì§ˆ": ["í•˜ì²œ ì •í™”", "ìƒìˆ˜ë„ ê°œì„ ", "í•˜ìˆ˜ì²˜ë¦¬", "ìˆ˜ì§ˆ ëª¨ë‹ˆí„°ë§", "ë¬¼ ì ˆì•½", "ë¹—ë¬¼ ì €ì¥", "í•˜ì²œ ìƒíƒœ ë³µì›", "ì •ìˆ˜ì¥ í˜„ëŒ€í™”", "ìƒìˆ˜ë„ ëˆ„ìˆ˜ ë°©ì§€", "ì§€í•˜ìˆ˜ ê´€ë¦¬", "ë…¹ì¡° ê´€ë¦¬", "ìˆ˜ë³€ ì •í™”"],
                "íê¸°ë¬¼": ["ì“°ë ˆê¸° ê°ëŸ‰", "ì¬í™œìš©", "ìŒì‹ë¬¼ì“°ë ˆê¸°", "ì¼íšŒìš©í’ˆ ê·œì œ", "íê¸°ë¬¼ ë¶„ë¦¬ë°°ì¶œ", "ìì›ìˆœí™˜", "ì¬í™œìš©ì„¼í„°", "ë¦¬í•„ìŠ¤í…Œì´ì…˜", "í”Œë¼ìŠ¤í‹± ì¤„ì´ê¸°", "ìƒí™œì“°ë ˆê¸° ì¢…ëŸ‰ì œ", "ëŒ€í˜•íê¸°ë¬¼ ìˆ˜ê±°", "ë¶ˆë²•íˆ¬ê¸° ë‹¨ì†", "ì¬í™œìš© ë§ˆì„", "ì—…ì‚¬ì´í´ë§"],
                "ì—ë„ˆì§€": ["ì‹ ì¬ìƒì—ë„ˆì§€", "íƒœì–‘ê´‘", "í’ë ¥", "ì—ë„ˆì§€ íš¨ìœ¨í™”", "ì ˆì „", "ì—ë„ˆì§€ ì €ì¥", "ìŠ¤ë§ˆíŠ¸ê·¸ë¦¬ë“œ", "ì œë¡œì—ë„ˆì§€ ê±´ì¶•", "ì—ë„ˆì§€ ìë¦½ë§ˆì„", "ìˆ˜ì†Œì—ë„ˆì§€", "ì§€ì—´ì—ë„ˆì§€", "LED ì¡°ëª… êµì²´", "ê±´ë¬¼ ì—ë„ˆì§€ê´€ë¦¬", "ì—ë„ˆì§€ ì§„ë‹¨"],
                "ê¸°í›„ë³€í™”": ["íƒ„ì†Œì¤‘ë¦½", "ì˜¨ì‹¤ê°€ìŠ¤ ê°ì¶•", "ê¸°í›„ ì ì‘", "ESG", "íƒ„ì†Œë°°ì¶œê¶Œ", "ê¸°í›„ìœ„ê¸° ëŒ€ì‘", "ê·¸ë¦°ë‰´ë”œ", "Net-Zero", "ê¸°í›„ë³€í™” êµìœ¡", "íƒ„ì†Œë°œìêµ­", "ê¸°í›„ ì·¨ì•½ê³„ì¸µ ì§€ì›", "í­ì—¼ ëŒ€ì‘", "í•œíŒŒ ëŒ€ë¹„"],
                "ë…¹ì§€": ["ë„ì‹œìˆ²", "ê³µì› ì¡°ì„±", "ê°€ë¡œìˆ˜", "ì˜¥ìƒë…¹í™”", "ë²½ë©´ë…¹í™”", "ìƒíƒœê³µì›", "ìŠµì§€ ë³´í˜¸", "ìƒë¬¼ë‹¤ì–‘ì„±", "ë„ì‹¬ ìˆ²ê¸¸", "ë¯¸ì„¸ë¨¼ì§€ ì°¨ë‹¨ìˆ²", "ë…¹ì§€ì¶• ì—°ê²°", "ë‚˜ë¬´ ì‹¬ê¸°", "ì •ì›ë„ì‹œ"]
            },
            "êµí†µ": {
                "ëŒ€ì¤‘êµí†µ": ["ë²„ìŠ¤ ë…¸ì„  ê°œí¸", "ì§€í•˜ì²  í™•ì¶©", "í™˜ìŠ¹ í¸ì˜", "ìš”ê¸ˆ ì •ì±…", "ì‹¬ì•¼ë²„ìŠ¤", "ê´‘ì—­ë²„ìŠ¤", "ë§ˆì„ë²„ìŠ¤", "ì €ìƒë²„ìŠ¤", "êµí†µì¹´ë“œ í†µí•©", "ì‹¤ì‹œê°„ ë„ì°© ì •ë³´", "BRT", "ë²„ìŠ¤ ì „ìš©ì°¨ë¡œ", "í™˜ìŠ¹ì„¼í„°", "ëŒ€ì¤‘êµí†µ ìš”ê¸ˆ í• ì¸", "ë¬´ë£Œí™˜ìŠ¹"],
                "ì£¼ì°¨": ["ê³µì˜ì£¼ì°¨ì¥", "ì£¼ì°¨ë‚œ í•´ì†Œ", "ë¶ˆë²•ì£¼ì°¨ ë‹¨ì†", "ê³µìœ ì£¼ì°¨", "ì£¼ì°¨ì¥ í™•ì¶©", "ê±°ì£¼ììš°ì„ ì£¼ì°¨", "ê³µê³µì£¼ì°¨ì¥", "ì£¼ì°¨ìš”ê¸ˆ ì •ì±…", "ë…¸ìƒì£¼ì°¨ì¥", "ê¸°ê³„ì‹ ì£¼ì°¨ì¥", "ì£¼ì°¨ì •ë³´ ì‹œìŠ¤í…œ", "ì£¼ì°¨ ê³µê°„ ê³µìœ ", "ì£¼ì°¨ ì•±", "ì¹œí™˜ê²½ ì£¼ì°¨ì¥"],
                "ë³´í–‰": ["ë³´í–‰ì ìš°ì„ ", "ë³´í–‰ë¡œ í™•ì¶©", "íš¡ë‹¨ë³´ë„ ê°œì„ ", "ë¬´ì¥ì•  ë„ë¡œ", "ë³´í–‰ê¶Œ ë³´ì¥", "ë³´í–‰í™˜ê²½ ê°œì„ ", "ë³´í–‰ì„¬", "ë³´í–‰ì‹ í˜¸ ì—°ì¥", "ë³´í–‰ ì•ˆì „", "ìŠ¤ì¿¨ì¡´", "ì‹¤ë²„ì¡´", "ì•ˆì „í•œ í†µí•™ë¡œ", "ë³´í–‰ì ì „ìš©ê±°ë¦¬", "ë³´ì°¨ë¶„ë¦¬"],
                "ìì „ê±°": ["ìì „ê±° ë„ë¡œ", "ê³µìœ ìì „ê±°", "ìì „ê±° ì£¼ì°¨ì¥", "ì•ˆì „ ì¸í”„ë¼", "ìì „ê±° ë„ë¡œë§", "ë”°ë¦‰ì´", "ìì „ê±° ìˆ˜ë¦¬ì†Œ", "ìì „ê±° ê±°ì¹˜ëŒ€", "ìì „ê±° ë³´ê´€ì†Œ", "ìì „ê±° êµìœ¡", "ìì „ê±° ì•ˆì „ëª¨", "ìì „ê±° ìš°ì„ ë„ë¡œ"],
                "êµí†µì•ˆì „": ["êµí†µì‚¬ê³  ì˜ˆë°©", "ê³¼ì† ë‹¨ì†", "ì‹ í˜¸ìœ„ë°˜ ë‹¨ì†", "ìŒì£¼ìš´ì „ ë‹¨ì†", "êµí†µì•½ì ë³´í˜¸", "êµí†µì•ˆì „ êµìœ¡", "ì–´ë¦°ì´ë³´í˜¸êµ¬ì—­", "ë…¸ì¸ë³´í˜¸êµ¬ì—­", "êµí†µì„¬", "ê³¼ì†ë°©ì§€í„±", "ì•ˆì „í‘œì§€íŒ", "ì‹ í˜¸ë“± ê°œì„ "],
                "ìŠ¤ë§ˆíŠ¸ êµí†µ": ["ITS", "êµí†µì •ë³´ ì‹œìŠ¤í…œ", "ì‹ í˜¸ì œì–´ ì‹œìŠ¤í…œ", "êµí†µë°ì´í„°", "ìŠ¤ë§ˆíŠ¸ ì‹ í˜¸ë“±", "AI êµí†µê´€ë¦¬", "ììœ¨ì£¼í–‰", "ëª¨ë¹Œë¦¬í‹°", "ê³µìœ ëª¨ë¹Œë¦¬í‹°", "ì „ê¸°ì°¨ ì¶©ì „ì†Œ", "ìˆ˜ì†Œì°¨ ì¶©ì „ì†Œ", "í‚¥ë³´ë“œ ì •ì±…"]
            },
            "ë³µì§€": {
                "ë…¸ì¸ë³µì§€": ["ê²½ë¡œë‹¹ ì§€ì›", "ëŒë´„ ì„œë¹„ìŠ¤", "ì¼ìë¦¬ ì°½ì¶œ", "ê±´ê°•ê´€ë¦¬", "ì¹˜ë§¤ ì˜ˆë°©", "ë…¸ì¸ ì—¬ê°€", "íš¨ë„ìˆ˜ë‹¹", "ê²½ë¡œìš°ëŒ€", "ì‹¤ë²„ì¹´í˜", "ë…¸ì¸ ì¼ìë¦¬", "ë…¸ì¸ ëŒë´„", "ë…ê±°ë…¸ì¸ ì§€ì›", "ì–´ë¥´ì‹  ê¸‰ì‹", "ë…¸ì¸ë³µì§€ê´€", "ì¹˜ë§¤ ì•ˆì‹¬ì„¼í„°", "ë…¸ì¸ ê±´ê°•ê²€ì§„", "ë…¸ì¸ ì˜ë£Œì§€ì›", "íš¨ë„ê´€ê´‘", "ì‹¤ë²„íƒ€ìš´"],
                "ì•„ë™ë³µì§€": ["ë³´ìœ¡ ì§€ì›", "ë†€ì´í„° í™•ì¶©", "ì•„ë™í•™ëŒ€ ì˜ˆë°©", "ë°©ê³¼í›„ ëŒë´„", "ì–´ë¦°ì´ì§‘ í™•ì¶©", "êµ­ê³µë¦½ ì–´ë¦°ì´ì§‘", "ë³´ìœ¡ë£Œ ì§€ì›", "ì•„ë™ìˆ˜ë‹¹", "ì¶œì‚°ì¥ë ¤ê¸ˆ", "ìœ¡ì•„íœ´ì§", "ë†€ì´í„° ì•ˆì „", "ì•„ì´ëŒë´„ ì„œë¹„ìŠ¤", "ì•„ë™ê¸‰ì‹", "ì•„ë™ë³´í˜¸", "ì•„ë™ì„¼í„°"],
                "ì²­ë…„ë³µì§€": ["ì£¼ê±° ì§€ì›", "ì·¨ì—… ì§€ì›", "ì²­ë…„ìˆ˜ë‹¹", "ì°½ì—… ì§€ì›", "ì²­ë…„ì£¼íƒ", "ì²­ë…„ ì¼ìë¦¬", "ì²­ë…„ ìˆ˜ë‹¹", "ì²­ë…„ ê³µê°„", "ì²­ë…„ ë¬¸í™”", "ì²­ë…„ í™œë™", "ì²­ë…„ ì •ì±…", "ì²­ë…„ ì°¸ì—¬", "ëŒ€í•™ìƒ ì§€ì›", "ì·¨ì—… êµìœ¡", "êµ¬ì§ ì§€ì›"],
                "ì¥ì• ì¸ë³µì§€": ["ì¥ì• ì¸ ì¼ìë¦¬", "í¸ì˜ì‹œì„¤", "ì´ë™ê¶Œ ë³´ì¥", "í™œë™ì§€ì›", "ì¥ì• ì¸ ë³µì§€ê´€", "ì¥ì• ì¸ ìˆ˜ë‹¹", "ì¬í™œì¹˜ë£Œ", "íŠ¹ìˆ˜êµìœ¡", "ì¥ì• ì¸ ì£¼ì°¨", "ì €ìƒë²„ìŠ¤", "ì¥ì• ì¸ ì²´ìœ¡", "ì¥ì• ì¸ ë¬¸í™”", "ì¥ì• ì¸ì½œíƒì‹œ", "ë¬´ì¥ì• ê³µê°„"],
                "ì—¬ì„±ë³µì§€": ["ì—¬ì„± ì¼ìë¦¬", "ê²½ë ¥ë‹¨ì ˆ ì˜ˆë°©", "ì—¬ì„± ì•ˆì „", "ì—¬ì„± í­ë ¥ ì˜ˆë°©", "ì—¬ì„± ë³µì§€ê´€", "ê²½ë‹¨ë…€ ì¬ì·¨ì—…", "ì—¬ì„± ì°½ì—…", "ì—¬ì„± ê±´ê°•", "ì—¬ì„± ìƒë‹´", "í•œë¶€ëª¨ ì§€ì›", "ë¯¸í˜¼ëª¨ ì§€ì›", "ì„±í‰ë“±", "ì—¬ì„± ì¹œí™”ë„ì‹œ"],
                "ì €ì†Œë“ì¸µ ì§€ì›": ["ê¸°ì´ˆìƒí™œë³´ì¥", "ê¸´ê¸‰ë³µì§€", "ìƒê³„ì§€ì›", "ì˜ë£Œì§€ì›", "êµìœ¡ì§€ì›", "ì£¼ê±°ì§€ì›", "ë³µì§€ì‚¬ê°ì§€ëŒ€", "í‘¸ë“œë±…í¬", "ë¬¼ê°€ì§€ì›", "ì—ë„ˆì§€ë°”ìš°ì²˜", "ë‚œë°©ë¹„ ì§€ì›", "ì·¨ì•½ê³„ì¸µ ë³´í˜¸"]
            },
            "êµìœ¡": {
                "í•™êµêµìœ¡": ["êµìœ¡ê³¼ì • ê°œì„ ", "í•™êµì‹œì„¤ í˜„ëŒ€í™”", "ë¬´ìƒê¸‰ì‹", "ëŒë´„êµì‹¤", "í•™êµ ì•ˆì „", "êµìœ¡í™˜ê²½ ê°œì„ ", "ìŠ¤ë§ˆíŠ¸ êµì‹¤", "êµìœ¡ ê¸°ìì¬", "ê¸‰ì‹ í’ˆì§ˆ", "í•™êµ ê³µê¸°ì²­ì •ê¸°", "í•™êµ ëƒ‰ë‚œë°©", "í•™êµ í™”ì¥ì‹¤", "í•™êµ ì²´ìœ¡ê´€", "í•™êµ ë„ì„œê´€", "êµìœ¡ ë³µì§€"],
                "í‰ìƒêµìœ¡": ["ì„±ì¸ êµìœ¡", "ì§ì—…í›ˆë ¨", "ì˜¨ë¼ì¸ ê°•ì¢Œ", "í•™ìŠµ ì§€ì›", "í‰ìƒí•™ìŠµê´€", "ì‹œë¯¼ëŒ€í•™", "ë¬¸í•´êµìœ¡", "í•™ë ¥ì¸ì •", "ìê²©ì¦ êµìœ¡", "ì¬êµìœ¡", "í‰ìƒí•™ìŠµë„ì‹œ"],
                "ìœ ì•„êµìœ¡": ["ìœ ì¹˜ì› í™•ì¶©", "êµ­ê³µë¦½ìœ ì¹˜ì›", "ìœ ì•„ êµìœ¡ë¹„", "ìœ ì•„ ëŒë´„", "ëˆ„ë¦¬ê³¼ì •", "ìœ ì•„ ì•ˆì „", "ìœ ì•„ ì²´í—˜", "ìœ ì•„ ê¸‰ì‹", "ìœ ì•„ ë†€ì´"],
                "íŠ¹ìˆ˜êµìœ¡": ["íŠ¹ìˆ˜í•™êµ", "íŠ¹ìˆ˜í•™ê¸‰", "í†µí•©êµìœ¡", "íŠ¹ìˆ˜êµì‚¬", "íŠ¹ìˆ˜êµìœ¡ ì§€ì›", "ë°œë‹¬ì¥ì•  êµìœ¡", "íŠ¹ìˆ˜êµìœ¡ ê¸°ìì¬", "ì¹˜ë£Œì§€ì›"],
                "ë°©ê³¼í›„Â·ëŒë´„": ["ë°©ê³¼í›„ í•™êµ", "ì´ˆë“±ëŒë´„", "ì•„ì¹¨ëŒë´„", "ì €ë…ëŒë´„", "ëŒë´„êµì‹¤ í™•ì¶©", "ì§€ì—­ì•„ë™ì„¼í„°", "ë‹¤í•¨ê»˜ëŒë´„ì„¼í„°", "ì²­ì†Œë…„ë°©ê³¼í›„ì•„ì¹´ë°ë¯¸"]
            },
            "ì•ˆì „": {
                "ì¬ë‚œì•ˆì „": ["í™”ì¬ ì˜ˆë°©", "ì§€ì§„ ëŒ€ë¹„", "íƒœí’ ëŒ€ë¹„", "ì¬ë‚œ ëŒ€ì‘ í›ˆë ¨", "ì†Œë°©ì‹œì„¤", "ì†Œí™”ê¸° ë³´ê¸‰", "í™”ì¬ê²½ë³´ê¸°", "ì¬ë‚œë¬¸ì", "ì¬ë‚œëŒ€í”¼ì†Œ", "í’ìˆ˜í•´ ëŒ€ë¹„", "ì‚°ì‚¬íƒœ ì˜ˆë°©", "ë¶•ê´´ì‚¬ê³  ì˜ˆë°©", "ê°€ìŠ¤ì•ˆì „", "ì „ê¸°ì•ˆì „", "ìŠ¹ê°•ê¸° ì•ˆì „", "í™”í•™ì‚¬ê³  ëŒ€ì‘", "ë°©ì‚¬ëŠ¥ ëŒ€ì‘", "ì•ˆì „ë¬¸í™”", "ì¬ë‚œì•ˆì „ êµìœ¡"],
                "ë²”ì£„ì˜ˆë°©": ["CCTV í™•ì¶©", "ì•ˆì‹¬ê·€ê°€", "í•™êµí­ë ¥ ì˜ˆë°©", "ì„±ë²”ì£„ ì˜ˆë°©", "ë²”ì£„ ì·¨ì•½ì§€ì—­", "ë°©ë²”ë“±", "ë¹„ìƒë²¨", "ì—¬ì„±ì•ˆì‹¬íƒë°°í•¨", "ì—¬ì„±ì•ˆì‹¬ê·€ê°“ê¸¸", "ì•„ë™ì•ˆì „", "ì‹¤ì¢…ì•„ë™ ì˜ˆë°©", "ê°€ì •í­ë ¥ ì˜ˆë°©", "ìŠ¤í† í‚¹ ì˜ˆë°©", "ë””ì§€í„¸ì„±ë²”ì£„ ì˜ˆë°©"],
                "ì‹í’ˆì•ˆì „": ["ì‹í’ˆìœ„ìƒ", "ìœ„ìƒì ê²€", "í•™êµê¸‰ì‹ ì•ˆì „", "ì‹ì¤‘ë… ì˜ˆë°©", "HACCP", "ì›ì‚°ì§€ í‘œì‹œ", "ì‹í’ˆê²€ì‚¬", "ìœ„ìƒë“±ê¸‰ì œ", "ë¶ˆëŸ‰ì‹í’ˆ ë‹¨ì†"],
                "ìƒí™œì•ˆì „": ["ì–´ë¦°ì´ë†€ì´í„° ì•ˆì „", "ìŠ¹ê°•ê¸° ì•ˆì „", "ì œí’ˆì•ˆì „", "ìƒí™œì²´ìœ¡ ì•ˆì „", "ìˆ˜ìƒì•ˆì „", "ë“±ì‚°ë¡œ ì•ˆì „", "ì•¼ì˜ì¥ ì•ˆì „", "ë ˆì €ì•ˆì „", "ì‹œì„¤ë¬¼ ì•ˆì „ì ê²€"],
                "ë³´ê±´ì•ˆì „": ["ê°ì—¼ë³‘ ì˜ˆë°©", "ë°©ì—­", "ê³µì¤‘ë³´ê±´", "ì˜ë£Œì•ˆì „", "ì •ì‹ ê±´ê°•", "ìì‚´ì˜ˆë°©", "ì½”ë¡œë‚˜19 ëŒ€ì‘", "ì˜ˆë°©ì ‘ì¢…", "ê±´ê°•ê²€ì§„"]
            },
            "ê²½ì œ": {
                "ì¼ìë¦¬": ["ì¼ìë¦¬ ì°½ì¶œ", "êµ¬ì§ ì§€ì›", "ì§ì—… í›ˆë ¨", "ê³ ìš© ì•ˆì •", "ì²­ë…„ì¼ìë¦¬", "ì¤‘ì¥ë…„ì¼ìë¦¬", "ì—¬ì„±ì¼ìë¦¬", "ë…¸ì¸ì¼ìë¦¬", "ì¥ì• ì¸ì¼ìë¦¬", "ì·¨ì—…ë°•ëŒíšŒ", "ì¼ìë¦¬ì„¼í„°", "ê³ ìš©ë³´í—˜", "ì§ì—…ìƒë‹´", "ì·¨ì—…ì•Œì„ ", "ì›Œë¼ë°¸"],
                "ì°½ì—…": ["ì°½ì—… êµìœ¡", "ìê¸ˆ ì§€ì›", "ë©˜í† ë§", "ê³µìœ  ì˜¤í”¼ìŠ¤", "ì°½ì—…ë³´ìœ¡ì„¼í„°", "ìŠ¤íƒ€íŠ¸ì—…", "ë²¤ì²˜ê¸°ì—…", "ì†Œìƒê³µì¸ ì§€ì›", "ì˜ˆë¹„ì°½ì—…ì", "1ì¸ì°½ì—…", "ì²­ë…„ì°½ì—…", "ì—¬ì„±ì°½ì—…", "ì‹œë‹ˆì–´ì°½ì—…"],
                "ì†Œìƒê³µì¸": ["ì†Œìƒê³µì¸ ì§€ì›", "ì „í†µì‹œì¥ í™œì„±í™”", "ê³¨ëª©ìƒê¶Œ ë³´í˜¸", "ìƒê°€ì„ëŒ€ì°¨ ë³´í˜¸", "ì°©í•œì„ëŒ€ì¸", "ë°°ë‹¬ì•± ìˆ˜ìˆ˜ë£Œ", "ê³µê³µë°°ë‹¬ì•±", "ì œë¡œí˜ì´", "ì†Œìƒê³µì¸ ëŒ€ì¶œ", "ì»¨ì„¤íŒ… ì§€ì›", "ì˜¨ë¼ì¸ íŒë¡œ"],
                "ì§€ì—­ê²½ì œ": ["ë¡œì»¬í‘¸ë“œ", "ì§€ì—­í™”í", "ì§€ì—­ìƒí’ˆê¶Œ", "ì§€ì—­ íŠ¹ì‚°í’ˆ", "ë¡œì»¬í¬ë¦¬ì—ì´í„°", "ë„ì‹œì¬ìƒ", "êµ¬ë„ì‹¬ í™œì„±í™”", "ì „í†µì‹œì¥", "ì¬ë˜ì‹œì¥", "ìƒê¶Œ í™œì„±í™”", "ì§€ì—­ ì¼ìë¦¬"],
                "ê¸°ì—…ì§€ì›": ["ì¤‘ì†Œê¸°ì—… ì§€ì›", "ê¸°ì—… ìœ ì¹˜", "ì‚°ì—…ë‹¨ì§€", "íˆ¬ììœ ì¹˜", "ìˆ˜ì¶œì§€ì›", "R&D ì§€ì›", "ê¸°ìˆ ê°œë°œ", "ê¸°ì—… ì»¨ì„¤íŒ…", "ê¸°ì—… ê¸ˆìœµ", "ê¸°ì—… êµìœ¡"]
            },
            "ë¬¸í™”": {
                "ë¬¸í™”ì‹œì„¤": ["ë¬¸í™”ì„¼í„°", "ë„ì„œê´€", "ë°•ë¬¼ê´€", "ë¯¸ìˆ ê´€", "ê³µì—°ì¥", "ì „ì‹œê´€", "ë¬¸í™”ê³µê°„", "ë¶ì¹´í˜", "ì‘ì€ë„ì„œê´€", "ë§ˆì„ë„ì„œê´€", "ê³µê³µë„ì„œê´€", "ë¬¸í™”ê³µì›", "ë¬¸í™”ê±°ë¦¬"],
                "ë¬¸í™”í–‰ì‚¬": ["ì¶•ì œ", "ê³µì—°", "ì „ì‹œ", "ì˜í™”ì œ", "ìŒì•…íšŒ", "ê±°ë¦¬ê³µì—°", "ë¬¸í™”ì˜ˆìˆ ì œ", "ì§€ì—­ì¶•ì œ", "ì „í†µë¬¸í™”ì¶•ì œ", "ê³„ì ˆì¶•ì œ", "ì•¼ê°„ë¬¸í™”í–‰ì‚¬", "ì£¼ë§ê³µì—°"],
                "ë¬¸í™”ì˜ˆìˆ ": ["ì˜ˆìˆ êµìœ¡", "ë¬¸í™”ê°•ì¢Œ", "ì˜ˆìˆ ë‹¨ì²´ ì§€ì›", "ì˜ˆìˆ ì¸ ì§€ì›", "ê³µê³µë¯¸ìˆ ", "ë¬¸í™”ì˜ˆìˆ  ë™ì•„ë¦¬", "ì•„ë§ˆì¶”ì–´ ì˜ˆìˆ ", "ìƒí™œì˜ˆìˆ ", "ì‹œë¯¼ì˜ˆìˆ ê°€", "ë¬¸í™”ë™í˜¸íšŒ"],
                "ì „í†µë¬¸í™”": ["ë¬¸í™”ì¬ ë³´ì¡´", "ì „í†µë¬¸í™” ê³„ìŠ¹", "í–¥í† ë¬¸í™”", "ë¬´í˜•ë¬¸í™”ì¬", "í•œì˜¥ë§ˆì„", "ì „í†µì‹œì¥", "ì „í†µìŒì‹", "ì „í†µê³µì˜ˆ", "ë¯¼ì†ë†€ì´", "ì „í†µì˜ë¡€"],
                "ê´€ê´‘": ["ê´€ê´‘ì§€ ê°œë°œ", "ê´€ê´‘ í™ë³´", "ê´€ê´‘ì•ˆë‚´", "ê´€ê´‘ì½”ìŠ¤", "ì²´í—˜ê´€ê´‘", "ìƒíƒœê´€ê´‘", "ë¬¸í™”ê´€ê´‘", "ì—­ì‚¬ê´€ê´‘", "ê´€ê´‘ìƒí’ˆ", "ê´€ê´‘ í¸ì˜ì‹œì„¤"]
            },
            "ì£¼ê±°": {
                "ê³µê³µì£¼íƒ": ["ê³µê³µì„ëŒ€", "ì˜êµ¬ì„ëŒ€", "êµ­ë¯¼ì„ëŒ€", "í–‰ë³µì£¼íƒ", "ë§¤ì…ì„ëŒ€", "ì „ì„¸ì„ëŒ€", "ê³µê³µë¶„ì–‘", "ê³µê³µì£¼íƒ í™•ì¶©", "ì£¼ê±°ë³µì§€", "ì£¼ê±°ê¸‰ì—¬", "ì£¼íƒë°”ìš°ì²˜"],
                "ì£¼ê±°í™˜ê²½": ["ë…¸í›„ì£¼íƒ ê°œì„ ", "ì£¼ê±°í™˜ê²½ ê°œì„ ", "ë¹ˆì§‘ì •ë¹„", "ì£¼íƒë¦¬ëª¨ë¸ë§", "ìŠ¬ë ˆì´íŠ¸ ì œê±°", "ì£¼íƒ ì—ë„ˆì§€íš¨ìœ¨", "ë‹¨ì—´ ê°œì„ ", "ë³´ì¼ëŸ¬ êµì²´", "ì£¼ê±° ì•ˆì „", "ì£¼íƒë°©ì—­"],
                "ì²­ë…„ì£¼ê±°": ["ì²­ë…„ì£¼íƒ", "ì²­ë…„ì„ëŒ€", "ì²­ë…„ì „ì„¸", "ì…°ì–´í•˜ìš°ìŠ¤", "ëŒ€í•™ìƒ ê¸°ìˆ™ì‚¬", "ì²­ë…„ ì£¼ê±°ë¹„ ì§€ì›", "ì²­ë…„ ì›”ì„¸ ì§€ì›", "ì²­ë…„ ì „ì„¸ìê¸ˆ"],
                "ì£¼ê±°ì·¨ì•½ê³„ì¸µ": ["ìª½ë°©ì´Œ", "ê³ ì‹œì›", "ë¹„ë‹í•˜ìš°ìŠ¤", "ì»¨í…Œì´ë„ˆ", "ë°˜ì§€í•˜", "ì˜¥íƒ‘ë°©", "ì£¼ê±°ë³µì§€ì„¼í„°", "ì£¼ê±°ìƒë‹´", "ì£¼ê±°ë¹„ ì§€ì›", "ê¸´ê¸‰ì£¼ê±°ì§€ì›"]
            },
            "ê±´ì„¤Â·ë„ì‹œ": {
                "ë„ì‹œê³„íš": ["ë„ì‹œì¬ìƒ", "ë„ì‹¬ì¬ê°œë°œ", "ë‰´íƒ€ìš´", "ë„ì‹œ ì •ë¹„", "ë„ì‹œì„¤ê³„", "ìŠ¤ë§ˆíŠ¸ì‹œí‹°", "ì¹œí™˜ê²½ë„ì‹œ", "ì••ì¶•ë„ì‹œ", "ì§ì£¼ê·¼ì ‘", "ë³µí•©ìš©ë„"],
                "ê±´ì„¤": ["í† ëª©ê³µì‚¬", "ë„ë¡œê±´ì„¤", "êµëŸ‰ê±´ì„¤", "í„°ë„ê³µì‚¬", "í•˜ì²œì •ë¹„", "ì œë°©", "í•­ë§Œ", "ì¸í”„ë¼", "ê³µê³µì‹œì„¤", "ì²´ìœ¡ì‹œì„¤ ê±´ì„¤"],
                "ë„ì‹œë¯¸ê´€": ["ê²½ê´€ ê°œì„ ", "ê°„íŒì •ë¹„", "ë¶ˆë²•ê´‘ê³ ë¬¼ ì •ë¹„", "ê°€ë¡œí™˜ê²½", "ë„ì‹œë””ìì¸", "ê³µê³µë””ìì¸", "ìƒ‰ì±„ê³„íš", "ì•¼ê°„ê²½ê´€", "ì¡°ëª…"],
                "ë§ˆì„ë§Œë“¤ê¸°": ["ì£¼ë¯¼ìì¹˜", "ë§ˆì„ê³µë™ì²´", "ë„ì‹œì¬ìƒ ë‰´ë”œ", "ê³¨ëª©ê¸¸ ì¬ìƒ", "ë§ˆì„ ì£¼ì°¨ì¥", "ë§ˆì„íšŒê´€", "ë§ˆì„ ê³µë™ì´ìš©ì‹œì„¤", "ë§ˆì„ í…ƒë°­", "ë§ˆì„ ì‰¼í„°"]
            },
            "ë†ì—…Â·ë†ì´Œ": {
                "ë†ì—…": ["ìŠ¤ë§ˆíŠ¸íŒœ", "ì¹œí™˜ê²½ë†ì—…", "ìœ ê¸°ë†", "ë„ì‹œë†ì—…", "ì£¼ë§ë†ì¥", "í…ƒë°­", "ë†ì—…ê¸°ìˆ ", "ë†ê¸°ê³„", "ë†ì—…ì¸ êµìœ¡", "ì²­ë…„ë†ì—…ì¸", "ê·€ë†"],
                "ë†ì´Œ": ["ë†ì´Œê°œë°œ", "ë†ì´Œê´€ê´‘", "ë†ì´Œì²´í—˜", "ê·€ì´Œ", "ë†ì´Œì£¼íƒ", "ë†ì´Œë³µì§€", "ë†ì´Œ ì˜ë£Œ", "ë†ì´Œ êµí†µ", "ë†ì´Œ ì¼ìë¦¬", "ë†ì´Œ ì¸êµ¬"],
                "ìœ í†µ": ["ì§ê±°ë˜ì¥í„°", "ë†ì‚°ë¬¼ ì§íŒì¥", "ë¡œì»¬í‘¸ë“œ", "ë†í˜‘íŒë§¤ì¥", "ì˜¨ë¼ì¸ íŒë§¤", "ë†ì‚°ë¬¼ ìˆ˜ì¶œ", "ë†ì‚°ë¬¼ ê°€ê³µ", "6ì°¨ ì‚°ì—…", "í‘¸ë“œí”Œëœ"]
            },
            "ë³´ê±´Â·ì˜ë£Œ": {
                "ê³µê³µì˜ë£Œ": ["ë³´ê±´ì†Œ", "ê³µê³µë³‘ì›", "ì˜ë£Œì·¨ì•½ì§€ì—­", "ê³µê³µì˜ë£Œ í™•ì¶©", "ì‘ê¸‰ì˜ë£Œ", "119êµ¬ê¸‰", "ì•¼ê°„ì§„ë£Œ", "íœ´ì¼ì§„ë£Œ", "ìˆœíšŒì§„ë£Œ"],
                "ê±´ê°•ì¦ì§„": ["ê±´ê°•ê²€ì§„", "ì˜ˆë°©ì ‘ì¢…", "ê±´ê°•êµìœ¡", "ê¸ˆì—°", "ì ˆì£¼", "ì˜ì–‘", "ìš´ë™", "ë¹„ë§Œì˜ˆë°©", "ë§Œì„±ì§ˆí™˜ ê´€ë¦¬", "ì•”ê²€ì§„", "êµ¬ê°•ê²€ì§„"],
                "ì •ì‹ ê±´ê°•": ["ì •ì‹ ê±´ê°• ë³µì§€ì„¼í„°", "ìì‚´ì˜ˆë°©", "ì‹¬ë¦¬ìƒë‹´", "íŠ¸ë¼ìš°ë§ˆ ì¹˜ë£Œ", "ì¤‘ë… ì¹˜ë£Œ", "ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë¦¬", "ìš°ìš¸ì¦", "ë¶ˆì•ˆì¥ì• ", "ì •ì‹ ê±´ê°• êµìœ¡"],
                "ì˜ë£Œì§€ì›": ["ì˜ë£Œë¹„ ì§€ì›", "ì·¨ì•½ê³„ì¸µ ì˜ë£Œ", "ë‚œì„ ì§€ì›", "ì¶œì‚° ì§€ì›", "ì˜ìœ ì•„ ê±´ê°•", "ë…¸ì¸ ì˜ë£Œ", "ì¥ì• ì¸ ì˜ë£Œ", "í¬ê·€ì§ˆí™˜", "ì¤‘ì¦ì§ˆí™˜"]
            },
            "ë””ì§€í„¸Â·ICT": {
                "ìŠ¤ë§ˆíŠ¸ë„ì‹œ": ["ìŠ¤ë§ˆíŠ¸ì‹œí‹°", "IoT", "ë¹…ë°ì´í„°", "AI í™œìš©", "ë””ì§€í„¸íŠ¸ìœˆ", "5G", "ê³µê³µì™€ì´íŒŒì´", "ë””ì§€í„¸ ì¸í”„ë¼", "í†µì‹ ë§"],
                "ì „ìì •ë¶€": ["ì „ìë¯¼ì›", "ì˜¨ë¼ì¸ í–‰ì •", "ëª¨ë°”ì¼ ì•±", "ë””ì§€í„¸ ì„œë¹„ìŠ¤", "í–‰ì •ì •ë³´ ê³µê°œ", "ë°ì´í„° ê°œë°©", "ê³µê³µë°ì´í„°", "ì •ë³´í™” ì‚¬ì—…"],
                "ë””ì§€í„¸ ê²©ì°¨ í•´ì†Œ": ["ë””ì§€í„¸ êµìœ¡", "ì •ë³´í™” êµìœ¡", "ì·¨ì•½ê³„ì¸µ ì •ë³´í™”", "ì‹œë‹ˆì–´ ITêµìœ¡", "ë””ì§€í„¸ ë¦¬í„°ëŸ¬ì‹œ", "í‚¤ì˜¤ìŠ¤í¬ êµìœ¡", "ìŠ¤ë§ˆíŠ¸í° êµìœ¡"],
                "ì •ë³´ë³´í˜¸": ["ê°œì¸ì •ë³´ ë³´í˜¸", "ì‚¬ì´ë²„ë³´ì•ˆ", "ì •ë³´ë³´ì•ˆ", "í•´í‚¹ ë°©ì§€", "í”¼ì‹± ì˜ˆë°©", "ëœì„¬ì›¨ì–´ ëŒ€ì‘", "ì •ë³´ë³´í˜¸ êµìœ¡"]
            },
            "ì²´ìœ¡": {
                "ìƒí™œì²´ìœ¡": ["ì²´ìœ¡ì‹œì„¤", "ì²´ìœ¡êµì‹¤", "ë™ë„¤ì²´ìœ¡ê´€", "ê³µê³µì²´ìœ¡ì‹œì„¤", "ìˆ˜ì˜ì¥", "í—¬ìŠ¤ì¥", "í…Œë‹ˆìŠ¤ì¥", "ì¶•êµ¬ì¥", "ë†êµ¬ì¥", "ë°°ë“œë¯¼í„´ì¥", "ì²´ìœ¡í”„ë¡œê·¸ë¨", "ìƒí™œì²´ìœ¡í´ëŸ½"],
                "ì „ë¬¸ì²´ìœ¡": ["ì„ ìˆ˜ ìœ¡ì„±", "ì²´ìœ¡ ê¿ˆë‚˜ë¬´", "ìœ ë§ì£¼ ë°œêµ´", "ì²´ìœ¡ ì˜ì¬", "ì—˜ë¦¬íŠ¸ ì²´ìœ¡", "ì „ë¬¸ì²´ìœ¡ì¸ ì§€ì›", "ì²´ìœ¡ëŒ€íšŒ ê°œìµœ"],
                "ê±´ê°•ì²´ìœ¡": ["ê±·ê¸°ìš´ë™", "ë“±ì‚°", "ìì „ê±°íƒ€ê¸°", "êµ­ë¯¼ì²´ì¡°", "ê±´ê°• í”„ë¡œê·¸ë¨", "ê±´ê°•ê±·ê¸°", "íŠ¸ë ˆí‚¹", "ë§ˆë¼í†¤", "ì‚°ì±…ë¡œ"]
            },
            "ê³¼í•™Â·ê¸°ìˆ ": {
                "R&D": ["ì—°êµ¬ê°œë°œ", "ê¸°ìˆ ê°œë°œ", "ì‹ ê¸°ìˆ ", "ì‚°í•™í˜‘ë ¥", "ì—°êµ¬ì§€ì›", "ì—°êµ¬ì†Œ", "ì‹¤í—˜ì‹¤", "ê¸°ìˆ ì‚¬ì—…í™”", "ê¸°ìˆ ì´ì „"],
                "í˜ì‹ ": ["í˜ì‹ ì„±ì¥", "ê¸°ìˆ í˜ì‹ ", "ì‚°ì—…í˜ì‹ ", "ë””ì§€í„¸ ì „í™˜", "ê·¸ë¦°ì „í™˜", "ë¯¸ë˜ê¸°ìˆ ", "ì²¨ë‹¨ê¸°ìˆ ", "4ì°¨ì‚°ì—…", "ë°”ì´ì˜¤", "ë‚˜ë…¸", "ë¡œë´‡"],
                "ê³¼í•™ë¬¸í™”": ["ê³¼í•™ê´€", "ê³¼í•™ì²´í—˜", "ê³¼í•™êµìœ¡", "ê³¼í•™ì¶•ì œ", "ë©”ì´ì»¤ìŠ¤í˜ì´ìŠ¤", "ê³¼í•™ë™ì•„ë¦¬", "ë°œëª…êµìœ¡", "ì½”ë”©êµìœ¡"]
            },
            "í–‰ì •Â·ì°¸ì—¬": {
                "ì£¼ë¯¼ì°¸ì—¬": ["ì£¼ë¯¼ìì¹˜", "ì£¼ë¯¼ì°¸ì—¬ì˜ˆì‚°", "ë§ˆì„íšŒì˜", "ì£¼ë¯¼ì´íšŒ", "ê³µë¡ í™”", "ì£¼ë¯¼íˆ¬í‘œ", "ì£¼ë¯¼ì œì•ˆ", "ì£¼ë¯¼ì†Œí†µ", "ì‹œë¯¼ì°¸ì—¬"],
                "ë¯¼ì›": ["ë¯¼ì›ì²˜ë¦¬", "ì›ìŠ¤í†± ë¯¼ì›", "ì°¾ì•„ê°€ëŠ” ë¯¼ì›", "ë¬´ì¸ë¯¼ì›ë°œê¸‰ê¸°", "ë¯¼ì›ìƒë‹´", "ê³ ì¶©ë¯¼ì›", "ë¯¼ì› ë§Œì¡±ë„"],
                "ì—´ë¦°í–‰ì •": ["ì •ë³´ê³µê°œ", "í–‰ì •íˆ¬ëª…ì„±", "ì‹œë¯¼ê°ì‚¬ê´€", "ì˜´ë¶€ì¦ˆë§Œ", "ì²­ë ´ë„", "ë°˜ë¶€íŒ¨", "ê³µìµì‹ ê³ ", "í–‰ì •í˜ì‹ "],
                "ì†Œí†µÂ·í™ë³´": ["ì‹œë¯¼ì†Œí†µ", "ì •ì±…í™ë³´", "SNS ì†Œí†µ", "ì–¸ë¡ í™ë³´", "ì‹œì •ì†Œì‹", "ì£¼ë¯¼ì„¤ëª…íšŒ", "ê°„ë‹´íšŒ", "íƒ€ìš´í™€ë¯¸íŒ…"]
            }
        }
        
        # ì„ íƒ ë²„íŠ¼ì´ ëˆŒë ¸ì„ ë•Œ
        if "temp_selection" in st.session_state and st.session_state.temp_selection:
            st.session_state.selected_category = st.session_state.temp_selection
            st.session_state.temp_selection = ""
        
        # ì •ì±… ì¹´í…Œê³ ë¦¬ ì…ë ¥ì°½
        policy_category = st.text_input(
            "ì •ì±… ì¹´í…Œê³ ë¦¬ *",
            value=st.session_state.selected_category if st.session_state.selected_category else "",
            placeholder="ì˜ˆ: í™”ì¬, ì²­ë…„, ì£¼ì°¨ ë“± ì…ë ¥í•˜ë©´ ìë™ì™„ì„±ë©ë‹ˆë‹¤",
            help="í•œ ê¸€ìì”© ì…ë ¥í•˜ë©´ ê´€ë ¨ ì¹´í…Œê³ ë¦¬ê°€ ìë™ìœ¼ë¡œ ì¶”ì²œë©ë‹ˆë‹¤"
        )
        
        # ì‚¬ìš©ìê°€ ì§ì ‘ ì…ë ¥í•˜ë©´ ì—…ë°ì´íŠ¸
        if policy_category != st.session_state.selected_category:
            st.session_state.selected_category = policy_category
        
        # ì‹¤ì‹œê°„ ìë™ì™„ì„± (ëª¨ë°”ì¼/PC ë¶„ê¸°)
        if policy_category and len(policy_category) > 0:
            autocomplete_suggestions = []
            
            for main_cat, sub_cats in category_database.items():
                for sub_cat, items in sub_cats.items():
                    for item in items:
                        full_path = f"{main_cat} > {sub_cat} > {item}"
                        if policy_category.lower() in full_path.lower():
                            autocomplete_suggestions.append(full_path)
            
            if autocomplete_suggestions:
                st.markdown("##### ğŸ’¡ ìë™ì™„ì„± ì¶”ì²œ")
                st.caption(f"{len(autocomplete_suggestions)}ê°œ í•­ëª© ë°œê²¬ (ìµœëŒ€ 10ê°œ í‘œì‹œ)")
                
                # ìë™ì™„ì„± í‘œì‹œ
                for idx, suggestion in enumerate(autocomplete_suggestions[:10]):
                    cols = st.columns([5, 1])
                    with cols[0]:
                        st.markdown(f"âœ¨ {suggestion}")
                    with cols[1]:
                        if st.button("ì„ íƒ", key=f"autocomplete_{idx}", use_container_width=True):
                            st.session_state.temp_selection = suggestion
                            st.rerun()
                
                if len(autocomplete_suggestions) > 10:
                    st.caption(f"+ {len(autocomplete_suggestions) - 10}ê°œ ë” ìˆìŠµë‹ˆë‹¤.")
        else:
            # ì…ë ¥ì´ ì—†ì„ ë•ŒëŠ” ë„ì›€ë§ë§Œ í‘œì‹œ (ëª¨ë°”ì¼ ìµœì í™”)
            st.caption("ğŸ’¡ ì¹´í…Œê³ ë¦¬ ì…ë ¥ ì‹œ ìë™ì™„ì„±ì´ í‘œì‹œë©ë‹ˆë‹¤. ë˜ëŠ” ì•„ë˜ ì „ì²´ ì¹´í…Œê³ ë¦¬ì—ì„œ ì„ íƒí•˜ì„¸ìš”.")
        
        # ì „ì²´ ì¹´í…Œê³ ë¦¬ ë¦¬ìŠ¤íŠ¸ í‘œì‹œ (expanderë¡œ)
        with st.expander("ğŸ“š ì „ì²´ ì¹´í…Œê³ ë¦¬ ëª©ë¡ ë³´ê¸° (í´ë¦­í•˜ì—¬ ì„ íƒ)"):
            st.caption("ì›í•˜ëŠ” ì„¸ë¶€ í•­ëª©ì„ í´ë¦­í•˜ë©´ ìë™ìœ¼ë¡œ ì…ë ¥ë©ë‹ˆë‹¤")
            
            for main_cat, sub_cats in category_database.items():
                st.markdown(f"#### {main_cat}")
                for sub_cat, items in sub_cats.items():
                    st.markdown(f"**{sub_cat}**")
                    
                    # ì„¸ë¶€ í•­ëª©ë§ˆë‹¤ ì„ íƒ ë²„íŠ¼
                    for item in items:
                        cols = st.columns([4, 1])
                        with cols[0]:
                            st.write(f"â€¢ {item}")
                        with cols[1]:
                            if st.button("ì„ íƒ", key=f"select_full_{main_cat}_{sub_cat}_{item}", use_container_width=True):
                                st.session_state.temp_selection = f"{main_cat} > {sub_cat} > {item}"
                                st.rerun()
                    
                    st.divider()
        
        target_audience = st.selectbox(
            "ì£¼ìš” ëŒ€ìƒ *",
            options=list(TARGET_AUDIENCES.keys()),
            help="ì •ì±…ì˜ ì£¼ìš” ëŒ€ìƒ ê·¸ë£¹"
        )
        
        if target_audience in TARGET_AUDIENCES:
            audience_info = TARGET_AUDIENCES[target_audience]
            st.info(f"**í†¤**: {audience_info['tone']}\n\n**ì´ˆì **: {audience_info['focus']}")
    
    with col2:
        policy_description = st.text_area(
            "ì •ì±… ì„¤ëª… *",
            height=150,
            placeholder="ì •ì±…ì˜ ë°°ê²½, ëª©ì , ê¸°ëŒ€ íš¨ê³¼ ë“±ì„ ìì„¸íˆ ì…ë ¥í•˜ì„¸ìš”"
        )
        
        keywords = st.text_input(
            "ê°•ì¡° í‚¤ì›Œë“œ (ì‰¼í‘œë¡œ êµ¬ë¶„)",
            placeholder="ì˜ˆ: ì‹œë¯¼ì°¸ì—¬, ë°ì´í„°ê¸°ë°˜, ì§€ì†ê°€ëŠ¥ì„±"
        )
        
        constraints = st.text_area(
            "ì œì•½ ì¡°ê±´ (ì„ íƒ)",
            height=100,
            placeholder="ì˜ˆ: ì˜ˆì‚° 1ì–µ ì´ë‚´, 3ê°œì›” ì‹œë²”ìš´ì˜"
        )
    
    content_package = st.selectbox(
        "ì½˜í…ì¸  íŒ¨í‚¤ì§€",
        options=list(CONTENT_PACKAGES.keys())
    )
    
    st.info(f"**ì„ íƒí•œ íŒ¨í‚¤ì§€ í¬í•¨ í•­ëª©**: {', '.join(CONTENT_PACKAGES[content_package])}")
    
    col1, col2, col3 = st.columns([2, 2, 1])
    
    with col1:
        if st.button("ğŸ’¾ ì •ì±… ì €ì¥", use_container_width=True):
            if not policy_title or not policy_description:
                st.error("ì •ì±… ì œëª©ê³¼ ì„¤ëª…ì€ í•„ìˆ˜ì…ë‹ˆë‹¤")
            else:
                policy_id = create_policy(
                    title=policy_title,
                    category=policy_category,
                    target_audience=target_audience,
                    description=policy_description
                )
                st.session_state.current_policy_id = policy_id
                st.success(f"âœ… ì •ì±…ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤ (ID: {policy_id})")
                st.session_state.workflow_step = "ì‹¤í–‰"
    
    with col2:
        if st.button("ğŸš€ AI ë¶„ì„ ìƒì„±", use_container_width=True):
            if not policy_title or not policy_description:
                st.error("ì •ì±… ì œëª©ê³¼ ì„¤ëª…ì€ í•„ìˆ˜ì…ë‹ˆë‹¤")
            else:
                try:
                    if not st.session_state.current_policy_id:
                        policy_id = create_policy(
                            title=policy_title,
                            category=policy_category,
                            target_audience=target_audience,
                            description=policy_description
                        )
                        st.session_state.current_policy_id = policy_id
                    
                    with st.spinner("AIê°€ ì •ì±…ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤... (30-60ì´ˆ ì†Œìš”)"):
                        analysis, raw = generate_policy_analysis(
                            title=policy_title,
                            category=policy_category,
                            target_audience=target_audience,
                            description=policy_description,
                            keywords=keywords,
                            constraints=constraints
                        )
                        
                        if analysis:
                            st.session_state.current_analysis = analysis
                            save_policy_content(
                                st.session_state.current_policy_id,
                                "analysis",
                                analysis
                            )
                            st.success("âœ… AI ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                            st.session_state.show_results = True
                            st.session_state.workflow_step = "í™ë³´"
                            st.balloons()
                        else:
                            st.error(f"AI ë¶„ì„ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                            
                except Exception as e:
                    st.error(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

with tab2:
    st.markdown("### 2ï¸âƒ£ AI ìƒì„± ê²°ê³¼ (ì „ì²´ ë¶„ì„)")
    
    if st.session_state.current_analysis:
        analysis = st.session_state.current_analysis
        
        # ì •ì±… ê¸°íš
        with st.expander("ğŸ“‹ ì •ì±… ê¸°íš", expanded=True):
            if "policy_planning" in analysis:
                planning = analysis["policy_planning"]
                st.markdown(f"**ëª©í‘œ**: {planning.get('objective', '')}")
                st.markdown(f"**ëŒ€ìƒ ë¶„ì„**: {planning.get('target_analysis', '')}")
                
                st.markdown("**í•µì‹¬ ì „ëµ**:")
                for idx, strategy in enumerate(planning.get("key_strategies", []), 1):
                    st.write(f"{idx}. {strategy}")
                
                st.markdown("**ê¸°ëŒ€ íš¨ê³¼**:")
                for outcome in planning.get("expected_outcomes", []):
                    st.write(f"â€¢ {outcome}")
                
                if "timeline" in planning:
                    timeline = planning["timeline"]
                    st.markdown("**íƒ€ì„ë¼ì¸**:")
                    st.write(f"- ì¤€ë¹„: {timeline.get('preparation', '')}")
                    st.write(f"- ì‹œë²”ìš´ì˜: {timeline.get('pilot', '')}")
                    st.write(f"- í™•ëŒ€ì ìš©: {timeline.get('expansion', '')}")
        
        # ì‹¤í–‰ ê³„íš
        with st.expander("âš™ï¸ ì‹¤í–‰ ê³„íš"):
            if "execution_plan" in analysis:
                execution = analysis["execution_plan"]
                
                action_items = execution.get("action_items", [])
                if action_items:
                    st.markdown("**ì‹¤í–‰ í•­ëª©**:")
                    for item in action_items:
                        st.markdown(f"""
**{item.get('phase', '')}**
- ì‹¤í–‰ ë‚´ìš©: {item.get('action', '')}
- ë‹´ë‹¹: {item.get('responsible', '')}
- ê¸°ê°„: {item.get('timeline', '')}
""")
                
                if "resources_needed" in execution:
                    resources = execution["resources_needed"]
                    st.markdown("**í•„ìš” ìì›**:")
                    st.write(f"- ì˜ˆì‚°: {resources.get('budget_range', '')}")
                    st.write(f"- ì¸ë ¥: {resources.get('personnel', '')}")
                    st.write(f"- ì¸í”„ë¼: {resources.get('infrastructure', '')}")
                
                st.markdown("**ë¦¬ìŠ¤í¬ ê´€ë¦¬**:")
                for risk in execution.get("risk_management", []):
                    st.warning(f"âš ï¸ {risk.get('risk', '')}\n- ì˜í–¥: {risk.get('impact', '')}\n- ì™„í™”: {risk.get('mitigation', '')}")
        
        # ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì „ëµ
        with st.expander("ğŸ“£ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì „ëµ"):
            if "communication_strategy" in analysis:
                comm = analysis["communication_strategy"]
                
                st.markdown("**í•µì‹¬ ë©”ì‹œì§€**:")
                for msg in comm.get("key_messages", []):
                    st.write(f"â€¢ {msg}")
                
                if "channels" in comm:
                    st.markdown("**ì±„ë„ ì „ëµ**:")
                    for channel in comm.get("channels", []):
                        st.write(f"- {channel.get('channel', '')}: {channel.get('content_type', '')} ({channel.get('frequency', '')})")
                
                if "target_specific_messages" in comm:
                    st.markdown("**ëŒ€ìƒë³„ ë©”ì‹œì§€**:")
                    target_msgs = comm["target_specific_messages"]
                    for target, msg in target_msgs.items():
                        st.info(f"**{target}**: {msg}")
        
        # ì½˜í…ì¸  ì œì‘ ë¸Œë¦¬í”„
        with st.expander("ğŸ¨ ì½˜í…ì¸  ì œì‘ ë¸Œë¦¬í”„"):
            if "content_briefs" in analysis:
                briefs = analysis["content_briefs"]
                
                st.markdown("### ì´ë¯¸ì§€ ë¸Œë¦¬í”„ 1")
                if "image_brief_1" in briefs:
                    brief1 = briefs["image_brief_1"]
                    st.write(f"**ì»¨ì…‰**: {brief1.get('concept', '')}")
                    st.write(f"**ì¥ë©´**: {brief1.get('scene_description', '')}")
                    st.write(f"**ìŠ¤íƒ€ì¼**: {brief1.get('visual_style', '')}")
                    st.success(f"**ë©”ì‹œì§€**: {brief1.get('key_message', '')}")
                
                st.markdown("### ì´ë¯¸ì§€ ë¸Œë¦¬í”„ 2")
                if "image_brief_2" in briefs:
                    brief2 = briefs["image_brief_2"]
                    st.write(f"**ì»¨ì…‰**: {brief2.get('concept', '')}")
                    st.write(f"**ì¥ë©´**: {brief2.get('scene_description', '')}")
                    st.write(f"**ìŠ¤íƒ€ì¼**: {brief2.get('visual_style', '')}")
                    st.success(f"**ë©”ì‹œì§€**: {brief2.get('key_message', '')}")
                
                st.markdown("### ì˜ìƒ ë¸Œë¦¬í”„")
                if "video_brief" in briefs:
                    video = briefs["video_brief"]
                    st.write(f"**ê¸¸ì´**: {video.get('duration', '')}")
                    st.write(f"**ìŠ¤í† ë¦¬**: {video.get('narrative_arc', '')}")
                    st.write(f"**ìŠ¤íƒ€ì¼ ê°€ì´ë“œ**: {video.get('style_guide', '')}")
                    st.success(f"**CTA**: {video.get('call_to_action', '')}")
        
        # ë§ˆì¼€íŒ… ìë£Œ
        with st.expander("ğŸ“ ë§ˆì¼€íŒ… ìë£Œ"):
            if "marketing_materials" in analysis:
                marketing = analysis["marketing_materials"]
                
                st.markdown(f"### {marketing.get('slogan', '')}")
                st.markdown(f"**íƒœê·¸ë¼ì¸**: {marketing.get('tagline', '')}")
                st.write(marketing.get('elevator_pitch', ''))
                
                if "social_media_posts" in marketing:
                    st.markdown("**ì†Œì…œë¯¸ë””ì–´ ì½˜í…ì¸ **:")
                    for post in marketing.get("social_media_posts", []):
                        st.info(f"**{post.get('platform', '')}**\n{post.get('content', '')}\ní•´ì‹œíƒœê·¸: {', '.join(post.get('hashtags', []))}")
                
                st.markdown("**FAQ**:")
                for faq in marketing.get("faq", []):
                    with st.expander(faq.get("question", "")):
                        st.write(faq.get("answer", ""))
        
        # ì„±ê³¼ ì§€í‘œ (KPI)
        with st.expander("ğŸ“ˆ ì„±ê³¼ ì§€í‘œ (KPI)"):
            if "performance_metrics" in analysis:
                metrics = analysis["performance_metrics"]
                
                kpi_framework = metrics.get("kpi_framework", [])
                if kpi_framework:
                    for kpi in kpi_framework:
                        st.markdown(f"""
**{kpi.get('metric', '')}** ({kpi.get('category', '')})
- ì¸¡ì • ë°©ë²•: {kpi.get('measurement_method', '')}
- ëª©í‘œ ë²”ìœ„: {kpi.get('target_range', '')}
- ë°ì´í„° ì¶œì²˜: {kpi.get('data_source', '')}
""")
                
                if "success_criteria" in metrics:
                    st.markdown("**ì„±ê³µ ê¸°ì¤€**:")
                    for criteria in metrics.get("success_criteria", []):
                        st.write(f"âœ“ {criteria}")
                
                if "monitoring_plan" in metrics:
                    monitoring = metrics["monitoring_plan"]
                    st.markdown("**ëª¨ë‹ˆí„°ë§ ê³„íš**:")
                    st.write(f"- ì¼ê°„: {monitoring.get('daily', '')}")
                    st.write(f"- ì£¼ê°„: {monitoring.get('weekly', '')}")
                    st.write(f"- ì›”ê°„: {monitoring.get('monthly', '')}")
        
        # ì´í•´ê´€ê³„ì ê´€ë¦¬
        with st.expander("ğŸ¤ ì´í•´ê´€ê³„ì ê´€ë¦¬"):
            if "stakeholder_management" in analysis:
                stakeholder = analysis["stakeholder_management"]
                
                if "stakeholders" in stakeholder:
                    st.markdown("**ì´í•´ê´€ê³„ì ë¶„ì„**:")
                    for sh in stakeholder.get("stakeholders", []):
                        st.markdown(f"""
**{sh.get('group', '')}**
- ê´€ì‹¬ì‚¬: {sh.get('interests', '')}
- ì†Œí†µ ì „ëµ: {sh.get('engagement_strategy', '')}
""")
                
                if "objection_handling" in stakeholder:
                    st.markdown("**ë°˜ëŒ€ ì˜ê²¬ ëŒ€ì‘**:")
                    for obj in stakeholder.get("objection_handling", []):
                        st.warning(f"**ë°˜ëŒ€**: {obj.get('objection', '')}\n**ëŒ€ì‘**: {obj.get('response', '')}")
    
    else:
        st.info("ë¨¼ì € 'ì •ì±… ì…ë ¥' íƒ­ì—ì„œ ì •ì±… ì •ë³´ë¥¼ ì…ë ¥í•˜ê³  AI ë¶„ì„ì„ ìƒì„±í•´ì£¼ì„¸ìš”.")

with tab3:
    st.markdown("### 3ï¸âƒ£ ì´ë¯¸ì§€ ìë™ ìƒì„±")
    
    if st.session_state.current_analysis and "content_briefs" in st.session_state.current_analysis:
        briefs = st.session_state.current_analysis["content_briefs"]
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            image_size = st.selectbox("ì´ë¯¸ì§€ í¬ê¸°", IMAGE_SIZES)
        
        with col2:
            image_quality = st.selectbox("í’ˆì§ˆ", ["standard", "hd"])
        
        with col3:
            num_images = st.number_input("ìƒì„± ê°œìˆ˜", min_value=1, max_value=4, value=2)
        
        st.divider()
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ğŸ–¼ï¸ ì´ë¯¸ì§€ 1 ìƒì„±", use_container_width=True):
                if "image_brief_1" in briefs:
                    with st.spinner("ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤... (20-40ì´ˆ)"):
                        result = generate_policy_image(
                            briefs["image_brief_1"],
                            size=image_size,
                            quality=image_quality
                        )
                        if result:
                            img, img_bytes = result
                            st.session_state.generated_images.append({
                                "image": img,
                                "bytes": img_bytes,
                                "brief": "image_brief_1"
                            })
                            
                            if st.session_state.current_policy_id:
                                save_generated_media(
                                    st.session_state.current_policy_id,
                                    "image",
                                    img_bytes,
                                    generate_image_prompt(briefs["image_brief_1"]),
                                    {"size": image_size, "quality": image_quality}
                                )
                            
                            st.success("âœ… ì´ë¯¸ì§€ 1 ìƒì„± ì™„ë£Œ!")
                            st.rerun()
                        else:
                            st.error("ì´ë¯¸ì§€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")
        
        with col2:
            if st.button("ğŸ–¼ï¸ ì´ë¯¸ì§€ 2 ìƒì„±", use_container_width=True):
                if "image_brief_2" in briefs:
                    with st.spinner("ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤... (20-40ì´ˆ)"):
                        result = generate_policy_image(
                            briefs["image_brief_2"],
                            size=image_size,
                            quality=image_quality
                        )
                        if result:
                            img, img_bytes = result
                            st.session_state.generated_images.append({
                                "image": img,
                                "bytes": img_bytes,
                                "brief": "image_brief_2"
                            })
                            
                            if st.session_state.current_policy_id:
                                save_generated_media(
                                    st.session_state.current_policy_id,
                                    "image",
                                    img_bytes,
                                    generate_image_prompt(briefs["image_brief_2"]),
                                    {"size": image_size, "quality": image_quality}
                                )
                            
                            st.success("âœ… ì´ë¯¸ì§€ 2 ìƒì„± ì™„ë£Œ!")
                            st.rerun()
                        else:
                            st.error("ì´ë¯¸ì§€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")
        
        st.divider()
        
        if st.session_state.generated_images:
            st.markdown(f"### ìƒì„±ëœ ì´ë¯¸ì§€ ({len(st.session_state.generated_images)}ì¥)")
            
            cols = st.columns(2)
            for idx, img_data in enumerate(st.session_state.generated_images):
                with cols[idx % 2]:
                    st.image(img_data["image"], use_column_width=True)
                    st.caption(f"ì´ë¯¸ì§€ {idx+1}")
                    
                    buffer = BytesIO(img_data["bytes"])
                    st.download_button(
                        f"ğŸ’¾ ì´ë¯¸ì§€ {idx+1} ë‹¤ìš´ë¡œë“œ",
                        buffer,
                        file_name=f"policy_image_{idx+1}.png",
                        mime="image/png",
                        key=f"download_img_{idx}"
                    )
        else:
            st.info("ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ë ¤ë©´ ìœ„ì˜ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”")
    
    else:
        st.info("ë¨¼ì € AI ë¶„ì„ì„ ìƒì„±í•´ì£¼ì„¸ìš”")

with tab4:
    st.markdown("### 4ï¸âƒ£ ì˜ìƒ í”„ë¡¬í”„íŠ¸ ìƒì„± (10ì´ˆ 3ì¢… ìŠ¤íƒ€ì¼)")
    
    if st.session_state.current_analysis and "content_briefs" in st.session_state.current_analysis:
        briefs = st.session_state.current_analysis["content_briefs"]
        
        if "video_brief" in briefs:
            video_brief = briefs["video_brief"]
            
            st.info("ğŸ¬ **10ì´ˆ ì˜ìƒ 3ê°€ì§€ ìŠ¤íƒ€ì¼**ì´ ìë™ ìƒì„±ë©ë‹ˆë‹¤: ë‹¤íë©˜í„°ë¦¬, ì‹œë„¤ë§ˆí‹±, ëª¨ë˜ ë‹¤ì´ë‚´ë¯¹")
            
            if st.button("ğŸ¬ 10ì´ˆ ì˜ìƒ 3ì¢… í”„ë¡¬í”„íŠ¸ ìƒì„±", use_container_width=True, type="primary"):
                with st.spinner("3ê°€ì§€ ìŠ¤íƒ€ì¼ì˜ ì˜ìƒ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘..."):
                    prompts_3styles = generate_video_prompts_3styles(video_brief)
                    
                    if "video_prompts_3styles" not in st.session_state:
                        st.session_state.video_prompts_3styles = []
                    
                    st.session_state.video_prompts_3styles.append(prompts_3styles)
                    st.success("âœ… 10ì´ˆ ì˜ìƒ 3ì¢… í”„ë¡¬í”„íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.balloons()
            
            st.divider()
            
            # 3ì¢… ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸ í‘œì‹œ
            if "video_prompts_3styles" in st.session_state and st.session_state.video_prompts_3styles:
                st.markdown("### ğŸ“¹ ìƒì„±ëœ ì˜ìƒ í”„ë¡¬í”„íŠ¸")
                
                for set_idx, prompt_set in enumerate(st.session_state.video_prompts_3styles):
                    st.markdown(f"#### ì„¸íŠ¸ {set_idx + 1}")
                    
                    # ìŠ¤íƒ€ì¼ 1: ë‹¤íë©˜í„°ë¦¬
                    with st.expander("ğŸ¥ ìŠ¤íƒ€ì¼ 1: ë‹¤íë©˜í„°ë¦¬ ë¦¬ì–¼ë¦¬ì¦˜", expanded=True):
                        st.text_area(
                            "í”„ë¡¬í”„íŠ¸ (ë‹¤íë©˜í„°ë¦¬)",
                            prompt_set["documentary"],
                            height=400,
                            key=f"video_doc_{set_idx}"
                        )
                        
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.download_button(
                                "ğŸ’¾ ë‹¤ìš´ë¡œë“œ",
                                prompt_set["documentary"],
                                file_name=f"video_documentary_{set_idx+1}.txt",
                                mime="text/plain",
                                key=f"download_doc_{set_idx}",
                                use_container_width=True
                            )
                        with col2:
                            st.link_button("ğŸ¬ Sora", VIDEO_PLATFORMS["Sora"], use_container_width=True)
                        with col3:
                            st.link_button("ğŸš€ Runway", VIDEO_PLATFORMS["Runway"], use_container_width=True)
                        with col4:
                            st.link_button("ğŸ¥ Pika", VIDEO_PLATFORMS["Pika"], use_container_width=True)
                    
                    # ìŠ¤íƒ€ì¼ 2: ì‹œë„¤ë§ˆí‹±
                    with st.expander("ğŸ¬ ìŠ¤íƒ€ì¼ 2: ì‹œë„¤ë§ˆí‹± ë“œë¼ë§ˆ", expanded=True):
                        st.text_area(
                            "í”„ë¡¬í”„íŠ¸ (ì‹œë„¤ë§ˆí‹±)",
                            prompt_set["cinematic"],
                            height=400,
                            key=f"video_cine_{set_idx}"
                        )
                        
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.download_button(
                                "ğŸ’¾ ë‹¤ìš´ë¡œë“œ",
                                prompt_set["cinematic"],
                                file_name=f"video_cinematic_{set_idx+1}.txt",
                                mime="text/plain",
                                key=f"download_cine_{set_idx}",
                                use_container_width=True
                            )
                        with col2:
                            st.link_button("ğŸ¬ Sora", VIDEO_PLATFORMS["Sora"], use_container_width=True)
                        with col3:
                            st.link_button("ğŸš€ Runway", VIDEO_PLATFORMS["Runway"], use_container_width=True)
                        with col4:
                            st.link_button("ğŸ¥ Pika", VIDEO_PLATFORMS["Pika"], use_container_width=True)
                    
                    # ìŠ¤íƒ€ì¼ 3: ëª¨ë˜ ë‹¤ì´ë‚´ë¯¹
                    with st.expander("âš¡ ìŠ¤íƒ€ì¼ 3: ëª¨ë˜ ë‹¤ì´ë‚´ë¯¹", expanded=True):
                        st.text_area(
                            "í”„ë¡¬í”„íŠ¸ (ëª¨ë˜)",
                            prompt_set["modern_dynamic"],
                            height=400,
                            key=f"video_modern_{set_idx}"
                        )
                        
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.download_button(
                                "ğŸ’¾ ë‹¤ìš´ë¡œë“œ",
                                prompt_set["modern_dynamic"],
                                file_name=f"video_modern_{set_idx+1}.txt",
                                mime="text/plain",
                                key=f"download_modern_{set_idx}",
                                use_container_width=True
                            )
                        with col2:
                            st.link_button("ğŸ¬ Sora", VIDEO_PLATFORMS["Sora"], use_container_width=True)
                        with col3:
                            st.link_button("ğŸš€ Runway", VIDEO_PLATFORMS["Runway"], use_container_width=True)
                        with col4:
                            st.link_button("ğŸ¥ Pika", VIDEO_PLATFORMS["Pika"], use_container_width=True)
                    
                    st.divider()
            else:
                st.info("ìœ„ì˜ '10ì´ˆ ì˜ìƒ 3ì¢… í”„ë¡¬í”„íŠ¸ ìƒì„±' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”")
            
            st.divider()
            
            st.markdown("### ğŸ¥ ì˜ìƒ ì œì‘ í”Œë«í¼")
            st.caption("ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ì•„ë˜ í”Œë«í¼ì—ì„œ ì‚¬ìš©í•˜ì„¸ìš”")
            cols = st.columns(len(VIDEO_PLATFORMS))
            for idx, (platform, url) in enumerate(VIDEO_PLATFORMS.items()):
                with cols[idx]:
                    st.link_button(platform, url, use_container_width=True)
        
        else:
            st.info("ì˜ìƒ ë¸Œë¦¬í”„ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    else:
        st.info("ë¨¼ì € AI ë¶„ì„ì„ ìƒì„±í•´ì£¼ì„¸ìš”")

with tab5:
    st.markdown("### 5ï¸âƒ£ ê²°ê³¼ ë° ë‚´ë³´ë‚´ê¸°")
    
    if st.session_state.current_policy_id and st.session_state.current_analysis:
        policy = get_policy(st.session_state.current_policy_id)
        
        st.markdown("#### ì •ì±… ì •ë³´")
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ì •ì±… ID", policy['id'])
        with col2:
            st.metric("ì¹´í…Œê³ ë¦¬", policy['category'])
        with col3:
            st.metric("ëŒ€ìƒ", policy['target_audience'])
        with col4:
            st.metric("ìƒíƒœ", policy['status'])
        
        st.markdown(f"**ì œëª©**: {policy['title']}")
        st.markdown(f"**ì„¤ëª…**: {policy['description'][:100]}...")
        
        st.divider()
        
        st.markdown("#### ìƒì„±ëœ ì½˜í…ì¸ ")
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ì´ë¯¸ì§€", f"{len(st.session_state.generated_images)}ì¥")
        with col2:
            video_count = len(st.session_state.video_prompts_3styles)
            st.metric("ì˜ìƒ í”„ë¡¬í”„íŠ¸", f"{video_count}ì„¸íŠ¸")
        with col3:
            st.metric("AI ë¶„ì„", "ì™„ë£Œ" if st.session_state.current_analysis else "ì—†ìŒ")
        
        st.divider()
        
        st.markdown("#### ğŸ“¥ ë‹¤ìš´ë¡œë“œ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ğŸ“„ PDF ë³´ê³ ì„œ", use_container_width=True):
                with st.spinner("PDFë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                    # ì´ë¯¸ì§€ ë°”ì´íŠ¸ ìˆ˜ì§‘
                    image_bytes = [img['bytes'] for img in st.session_state.generated_images]
                    
                    # ì˜ìƒ í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸ ìˆ˜ì§‘
                    video_texts = []
                    for idx, prompt_set in enumerate(st.session_state.video_prompts_3styles, 1):
                        video_texts.append(f"[ì„¸íŠ¸ {idx} - ë‹¤íë©˜í„°ë¦¬]\n{prompt_set.get('documentary', '')}")
                        video_texts.append(f"[ì„¸íŠ¸ {idx} - ì‹œë„¤ë§ˆí‹±]\n{prompt_set.get('cinematic', '')}")
                        video_texts.append(f"[ì„¸íŠ¸ {idx} - ëª¨ë˜ ë‹¤ì´ë‚´ë¯¹]\n{prompt_set.get('modern_dynamic', '')}")
                    
                    pdf_bytes = create_pdf_report(
                        policy, 
                        st.session_state.current_analysis,
                        images=image_bytes if image_bytes else None,
                        video_prompts=video_texts if video_texts else None
                    )
                    st.download_button(
                        "ğŸ’¾ PDF ë‹¤ìš´ë¡œë“œ",
                        pdf_bytes,
                        file_name=f"policy_report_{policy['id']}.pdf",
                        mime="application/pdf",
                        use_container_width=True
                    )
        
        with col2:
            if st.button("ğŸ“¦ ì „ì²´ ZIP", use_container_width=True):
                with st.spinner("ZIP íŒŒì¼ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                    image_bytes = [img['bytes'] for img in st.session_state.generated_images]
                    
                    # ì˜ìƒ í”„ë¡¬í”„íŠ¸ 3ì¢… ëª¨ë‘ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
                    video_texts = []
                    for idx, prompt_set in enumerate(st.session_state.video_prompts_3styles, 1):
                        video_texts.append(f"[ì„¸íŠ¸ {idx} - ë‹¤íë©˜í„°ë¦¬]\n{prompt_set.get('documentary', '')}")
                        video_texts.append(f"[ì„¸íŠ¸ {idx} - ì‹œë„¤ë§ˆí‹±]\n{prompt_set.get('cinematic', '')}")
                        video_texts.append(f"[ì„¸íŠ¸ {idx} - ëª¨ë˜ ë‹¤ì´ë‚´ë¯¹]\n{prompt_set.get('modern_dynamic', '')}")
                    
                    # PDF ë¨¼ì € ìƒì„±
                    pdf_bytes = create_pdf_report(
                        policy, 
                        st.session_state.current_analysis,
                        images=image_bytes if image_bytes else None,
                        video_prompts=video_texts if video_texts else None
                    )
                    
                    # ZIP ìƒì„± (PDF í¬í•¨)
                    zip_bytes = create_zip_export(
                        policy,
                        st.session_state.current_analysis,
                        images=image_bytes,
                        video_prompts=video_texts if video_texts else None,
                        pdf_bytes=pdf_bytes
                    )
                    
                    st.download_button(
                        "ğŸ’¾ ZIP ë‹¤ìš´ë¡œë“œ",
                        zip_bytes,
                        file_name=f"policy_package_{policy['id']}.zip",
                        mime="application/zip",
                        use_container_width=True
                    )
    
    else:
        st.info("ì •ì±…ì„ ìƒì„±í•˜ê³  AI ë¶„ì„ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”")
